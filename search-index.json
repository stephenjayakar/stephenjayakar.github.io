[{"content":"This is probably something I\u0026rsquo;ll be updating over time but has helped me a ton when kicking off long-running agents.\nFind a hard problem. Something like creating a browser, adding raytracing to an old game, adding VR to an old game, decompiling an old game (are you starting to see a trend?) Get an agent structure that allows you to run an agent on an always-on machine. It should be the same platform as the machine that will run the \u0026ldquo;problem\u0026rdquo; - if it\u0026rsquo;s a game, probably Windows. I\u0026rsquo;m using Opencode + Kimaki to check in on Discord Ralph loops. I created a skill here. For the initial codebase, have it create a comprehensive PLAN.md, and then setup a Ralph Loop until the PLAN.md is complete. You can have it keep kicking off agents until there are no - [ ] left in the document. (But not necessarily last): make it so that the agent can somehow verify its output. A screenshot harness, the ability to directly set state to a certain position, are super super important as as your topic gets more niche, AI is less likely to output code that works on the first try. ","date":"2026-02-22","id":0,"permalink":"/posts/ai-hard-problems/","summary":"This is probably something I\u0026rsquo;ll be updating over time but has helped me a ton when kicking off long-running agents.\nFind a hard problem. Something like creating a browser, adding raytracing to an old game, adding VR to an old game, decompiling an old game (are you starting to see a trend?) Get an agent structure that allows you to run an agent on an always-on machine. It should be the same platform as the machine that will run the \u0026ldquo;problem\u0026rdquo; - if it\u0026rsquo;s a game, probably Windows. I\u0026rsquo;m using Opencode + Kimaki to check in on Discord Ralph loops. I created a skill here. For the initial codebase, have it create a comprehensive PLAN.md, and then setup a Ralph Loop until the PLAN.md is complete. You can have it keep kicking off agents until there are no - [ ] left in the document. (But not necessarily last): make it so that the agent can somehow verify its output. A screenshot harness, the ability to directly set state to a certain position, are super super important as as your topic gets more niche, AI is less likely to output code that works on the first try. ","tags":["tech"],"title":"How to solve hard problems with AI"},{"content":"AI Agents are now magic decompilers. Previously, I ran an agent-in-the-loop to try to decompile Super Smash Bros. Melee in Dec 2024 with gpt-4o, but found that the model didn\u0026rsquo;t tend to learn from its mistakes. Since then:\nModels have gotten smarter Tools have gotten better Other people have started to create skills \u0026amp; tools to help AI It\u0026rsquo;s not just a couple of functions here or there. I\u0026rsquo;ve merged around 20 functions, and have 80 more in review. Previously, it would take me 1 day a function. My results aren\u0026rsquo;t even the most impressive though. The writer of the decomp skills set a record for the most matches in a PR. Tons of people are using their own custom agents or just Claude Code in the Discord (channel is #smash-bros-melee) every day with great results. If this is something you\u0026rsquo;re interested in, come pop on by! We could always use more tokens ü§†.\nWhy autonomous agents are good at decompilation# I reinvestigated this project because of Cursor\u0026rsquo;s post on long-running autonomous coding. They attempted really hard tasks that a single LLM agent generally couldn\u0026rsquo;t do, like writing a browser from scratch or a Windows 7 emulator. I realized that decompilation was actually a great fit for this paradigm since it\u0026rsquo;s a hard but verifiable task ‚Äì in some ways, it\u0026rsquo;s an even better fit than writing a browser. Specifically, it\u0026rsquo;s verifiable (you just run the compiler) and its parallelizable (you split up agents by function).\nSo I did what anyone would do when they want a tool for themselves: I told Opus to make it. Behold, agent-runner:\nNow, this isn\u0026rsquo;t anything fancy; that\u0026rsquo;s kind of the point. It\u0026rsquo;s powered by an Anthropic API key, and Opus 4.6 is so smart that you don\u0026rsquo;t really need to handhold it that much. The tool is just a simple frontend, backend, and agent scaffold that gives it access to basic tools like bash, read_file, and write_file. It also has compaction that kicks in as the task runs for a while.\nThe tool works like this:\na PLANNER agent looks at the Melee codebase and identifies functions that haven\u0026rsquo;t been decompiled yet. It adds them to PLAN.md, which is the doc that tracks all the tasks that need to be done, as well as the completion of tasks It then spins up one WORKER per task After the workers finish, another agent acts as a JUDGE. The JUDGE assesses if the task is complete ‚Äì if so, it updates PLAN.md. Otherwise, it spins up another worker to attempt the task While I gave the agent access to all the tools I came up with to run an LLM in a loop while compiling the game, it actually wasn\u0026rsquo;t necessary. The agent(s) ended up completely shortcutting them and writing their own tools, bringing in the base decompiler (m2c), compiler, and scorer (objdiff).\nConclusion# Lots of people on Twitter have been talking about how incredible new AI models are, and that \u0026ldquo;you can just do things.\u0026rdquo; Honestly, this is the first thing that\u0026rsquo;s impressed me in a while. It\u0026rsquo;s been great that AI can basically do fullstack work, but that\u0026rsquo;s been true since last summer. These truly hard tasks that took tons of human hours are starting to crumble with LLM intelligence + better scaffolding. That\u0026rsquo;s both amazing and scary. Decompilation, instead of being a passion project with tons of human hours over years can instead become a couple of highly specialized people glueing together tons of token output.\nSo now it becomes a question of: what do you want to build? What will you give your tokens to?\n","date":"2026-02-10","id":1,"permalink":"/posts/magic-decomp/","summary":"AI Agents are now magic decompilers. Previously, I ran an agent-in-the-loop to try to decompile Super Smash Bros. Melee in Dec 2024 with gpt-4o, but found that the model didn\u0026rsquo;t tend to learn from its mistakes. Since then:\nModels have gotten smarter Tools have gotten better Other people have started to create skills \u0026amp; tools to help AI It\u0026rsquo;s not just a couple of functions here or there. I\u0026rsquo;ve merged around 20 functions, and have 80 more in review. Previously, it would take me 1 day a function. My results aren\u0026rsquo;t even the most impressive though. The writer of the decomp skills set a record for the most matches in a PR. Tons of people are using their own custom agents or just Claude Code in the Discord (channel is #smash-bros-melee) every day with great results. If this is something you\u0026rsquo;re interested in, come pop on by! We could always use more tokens ü§†.\n","tags":["tech"],"title":"AI is now a magic decompiler"},{"content":"Original Article\nI\u0026rsquo;ve felt this tension between \u0026ldquo;scrubs\u0026rdquo; and people trying to have fun, especially when playing competitive Smash. I do agree that it\u0026rsquo;s frustrating when people purport to be competitive but are actually scrubs. There are some points I think are missing though:\nGames can change over time, especially when you complain a ton. Within the last two decades in Melee, wobbling was discovered (2006) and then finally banned (2019). The technique was degenerate, and hated in almost all levels of play. If people just sucked it up and dealt with it, I don\u0026rsquo;t think it would have been banned. If you\u0026rsquo;re not familiar, wobbling results in you being unable to move and pummeled until you die for up to minutes at a time. Being competitive is great; but it\u0026rsquo;s not like being competitive and \u0026ldquo;having fun\u0026rdquo; are more or less honorable than each other. When you engage in an activity with someone else, the goal isn\u0026rsquo;t always to \u0026ldquo;completely crush them.\u0026rdquo; Sometimes, it\u0026rsquo;s just to have fun, right? In the case where some techniques aren\u0026rsquo;t \u0026ldquo;fun\u0026rdquo;, it seems fine to limit yourself from using them. If anything it\u0026rsquo;s a bit socially awkward if you can\u0026rsquo;t sense the mismatch in competitive drive and don\u0026rsquo;t tailor to what your gaming partner is expecting. ","date":"2025-10-13","id":2,"permalink":"/posts/re-scrubs/","summary":"Original Article\nI\u0026rsquo;ve felt this tension between \u0026ldquo;scrubs\u0026rdquo; and people trying to have fun, especially when playing competitive Smash. I do agree that it\u0026rsquo;s frustrating when people purport to be competitive but are actually scrubs. There are some points I think are missing though:\nGames can change over time, especially when you complain a ton. Within the last two decades in Melee, wobbling was discovered (2006) and then finally banned (2019). The technique was degenerate, and hated in almost all levels of play. If people just sucked it up and dealt with it, I don\u0026rsquo;t think it would have been banned. If you\u0026rsquo;re not familiar, wobbling results in you being unable to move and pummeled until you die for up to minutes at a time. Being competitive is great; but it\u0026rsquo;s not like being competitive and \u0026ldquo;having fun\u0026rdquo; are more or less honorable than each other. When you engage in an activity with someone else, the goal isn\u0026rsquo;t always to \u0026ldquo;completely crush them.\u0026rdquo; Sometimes, it\u0026rsquo;s just to have fun, right? In the case where some techniques aren\u0026rsquo;t \u0026ldquo;fun\u0026rdquo;, it seems fine to limit yourself from using them. If anything it\u0026rsquo;s a bit socially awkward if you can\u0026rsquo;t sense the mismatch in competitive drive and don\u0026rsquo;t tailor to what your gaming partner is expecting. ","tags":["gaming"],"title":"Re: Introducing...the Scrub"},{"content":"Score: 8/10\nHollow Knight: Silksong came out recently, and I got so much fomo as I had never completed the previous entry. I\u0026rsquo;ve attempted to clear the game 2 times, and just started my third playthrough. As of finishing this entry, I beat the final boss and ended up getting the 2nd best ending.\nHollow Knight is hard. If you only have a cursory interest in video games, I don\u0026rsquo;t recommend the game. As someone who is mildly masochistic and isn\u0026rsquo;t exactly good enough for Elden Ring, Hollow Knight is at the perfect threshold in difficulty for me where I can clear bosses after around 10 tries and a crashout in my journal.\nHowever, the reason I kept dropping the game was, after not picking up a save for a while, it\u0026rsquo;s too hard to figure out:\nwhere you are in the game\u0026rsquo;s progression where to go next And even when playing the game normally (so, playing a save continuously without dropping it), it for some reason has the Metroid problem of \u0026ldquo;what floor do I bomb\u0026rdquo; but worse. I think it\u0026rsquo;s because the maps are really large and winding, and pretty hard to navigate through. Sometimes, the obstacles are about 50% as challenging as a boss, which means you can often die or feel locked out.\nMy current mitigations are\u0026hellip; to cheat unfortunately. But it\u0026rsquo;s made playing the game a lot better. I am using this guide to roughly figure out where to go to next, and I\u0026rsquo;m save resetting.\nReason for writing a review# I am currently reading The Art of Game Design which made me want to become more intentional with video games that I consume. Over the years, I\u0026rsquo;ve dialed in loosely the types of gaming experiences that are meaningful to me. I think going through the exercise of actually grading games would be helpful, not just for me, but for when I recommend games to others.\nScore# I don\u0026rsquo;t think I\u0026rsquo;m ready to componenitize my rating system, so I\u0026rsquo;ll give it an 8/10 overall. Here\u0026rsquo;s why:\nThe game would be a 9/10 if it was easier to figure out what to do next. Not even necessarily objective markers, but maybe better ways to notate the map. It\u0026rsquo;s also absurd that a compass takes up a slot. It\u0026rsquo;s kind of basic in Metroidvanias to be able to tell where you are on the map. I think the game developers had this fantasy of people maybe drawing out maps themselves to navigate through the game, but that\u0026rsquo;s simply too much work The environmental story was interesting and the strong commitment to aesthetic (never thought I\u0026rsquo;d see so many bugs) was compelling. This is perfectly integrated with the music and sound effects Combat was super satisfying, and as you get better, the curve of enjoyment increases. It seems deceptively simple at first, but the combination of additional abilities and increased mastery end up making it one of my favorite platformers of all time. I\u0026rsquo;m going to miss controlling this character\u0026hellip; which is fine because there\u0026rsquo;s the DLC + Silksong now! Once I had committed to using the guide, the anxiety around not finding the nearest bench to a boss encounter ended up going away and I was able to enter flow state a lot more. In general, the game was a better experience when I wasn\u0026rsquo;t anxious about something, which is why I recommend using a guide! ","date":"2025-09-27","id":3,"permalink":"/posts/hollow-knight/","summary":"Score: 8/10\nHollow Knight: Silksong came out recently, and I got so much fomo as I had never completed the previous entry. I\u0026rsquo;ve attempted to clear the game 2 times, and just started my third playthrough. As of finishing this entry, I beat the final boss and ended up getting the 2nd best ending.\nHollow Knight is hard. If you only have a cursory interest in video games, I don\u0026rsquo;t recommend the game. As someone who is mildly masochistic and isn\u0026rsquo;t exactly good enough for Elden Ring, Hollow Knight is at the perfect threshold in difficulty for me where I can clear bosses after around 10 tries and a crashout in my journal.\n","tags":["gaming"],"title":"Hollow Knight: much better with a guide!"},{"content":"Just so that people don\u0026rsquo;t get confused, this opencode. I\u0026rsquo;m not a shill I promise.\nTL;DR: if you have time to experiment, use opencode with sonnet-4. Otherwise, use Claude Code.\nI\u0026rsquo;ve spent a lot of time with opencode as well as Claude Code. I\u0026rsquo;m going to use this as a live document talking about the tradeoffs of using either tool.\nFirst, Claude Code is roughly SotA for a terminal AI editor for fullstack work (my domain). I\u0026rsquo;ve also tried:\nCursor with various models Claude Code, but overriding what model it uses to try GPT 4.1 Qwen code Aider Gemini CLI opencode was exciting to me as their CEO cares a lot about TUI excellence, and it was promising to have Claude Code level performance but with models that were not Anthropic\u0026rsquo;s. (this was before GPT-5) I was hoping that:\no3 would outperform sonnet-4, as I generally thought that o3 was a smarter model I could use Cerebras models at lightning speed. qwen-coder advertises \u0026gt; 5000 tokens / second on OpenRouter! This is a rant for another time, but I think SWEs are leaving a lot of cognitive performance on the table by going overly async on their work when using agents. Both of these hopes were dashed. o3 just didn\u0026rsquo;t perform as well as sonnet-4 is mysteriously nuts at using grep. Cerebras models on Openrouter have strict rate limits even if you pay, which sucks. The times it does work, however, I\u0026rsquo;d say that qwen-coder isn\u0026rsquo;t fully at sonnet-4 level.\nThe only benefit I can see to using Claude code over opencode is that for only using Anthropic models, it can be cheaper as it round-robins between different models depending on the task. Even if you set the model selector to opus, it uses haiku for some of the searches which really cuts cost. I don\u0026rsquo;t really have much more to add atm besides some upsides of using opencode:\nClaude code prints out to your terminal. opencode has its own buffer system. That means that you can resize your window and it\u0026rsquo;ll render properly, and scroll up and down more than your terminal\u0026rsquo;s limits. If you\u0026rsquo;ve ever used nano or emacs or vim, you might understand this better. opencode\u0026rsquo;s themes are really pretty Ability to add new models instantly and even use local models - I had limited success with local models unfortunately as you need a pretty fat context size to get results. ","date":"2025-08-29","id":4,"permalink":"/posts/opencode-claude/","summary":"Just so that people don\u0026rsquo;t get confused, this opencode. I\u0026rsquo;m not a shill I promise.\nTL;DR: if you have time to experiment, use opencode with sonnet-4. Otherwise, use Claude Code.\nI\u0026rsquo;ve spent a lot of time with opencode as well as Claude Code. I\u0026rsquo;m going to use this as a live document talking about the tradeoffs of using either tool.\nFirst, Claude Code is roughly SotA for a terminal AI editor for fullstack work (my domain). I\u0026rsquo;ve also tried:\n","tags":["tech"],"title":"`opencode` or Claude Code?"},{"content":"Reading the Bible in an academic fashion has taught me a skill that has been extremely useful when reading other historical texts, but seems to be something that modern readers seem to be losing. I notice this especially when people struggle to read anything older than X year (e.g. 1960), because it has concepts that they fundamentally disagree with.\nI call it ‚Äúempathy for the author.‚Äù When reading a text and trying to understand it, my first goal is to try to learn as much about the author as possible and their worldview. Then, I attempt to understand the points they‚Äôre making. I think other people should do the same.\nHere‚Äôs a specific controversy to ground my point - the New Testament‚Äôs views on slavery.\nSlaves, obey your earthly masters with respect and fear, and with sincerity of heart, just as you would obey Christ. Obey them not only to win their favor when their eye is on you, but as slaves of Christ, doing the will of God from your heart. Serve wholeheartedly, as if you were serving the Lord, not people, because you know that the Lord will reward each one for whatever good they do, whether they are slave or free. And masters, treat your slaves in the same way. Do not threaten them, since you know that he who is both their Master and yours is in heaven, and there is no favoritism with him.\nEphesians 6:5-9 [NIV]\nToday, we believe in the personal liberty of all. Autonomy is sacred; we‚Äôre willing to die so that others can have freedom. So reading text like the above can be difficult and triggering. Here‚Äôs a rough overview of responses I‚Äôve heard to this passage:\nDownplaying the meaning and implications of the text: ‚Äúslavery wasn‚Äôt that bad back then‚Äù or ‚Äúat least it wasn‚Äôt chattel slavery‚Äù Anger at how this passage seems to justify slavery: \u0026ldquo;Paul is saying that it\u0026rsquo;s okay for masters to keep on owning and controlling slaves, and that is unacceptable.\u0026rdquo; Not a prevalent interpretation now, but was used by slave owners in the US South in the past: ‚Äúthis passage justifies slavery so it is okay for us to own slaves‚Äù More complicated, but interpret the point Paul is making within historical context. (1) is intellectually dishonest. You could probably make an argument that the ceiling for how well a slave could be treated as well as their future prospects are lower in US chattel slavery. Also, some people in this camp try to weasel out by translating the word as ‚Äúservant,‚Äù as the KJV translation does that:\nServants, be obedient to them that are your masters according to the flesh, with fear and trembling, in singleness of your heart, as unto Christ;\nEphesians 6:5 [KJV]\nBut that isn‚Äôt a good translation based on the NET bible notes:\nTraditionally, ‚ÄúServants‚Äù (KJV). Though Œ¥Œø·ø¶ŒªŒøœÇ (doulos) is often translated ‚Äúservant,‚Äù the word does not bear the connotation of a free individual serving another.\n(2) and (3) make the error of assuming that the passage‚Äôs background setting is prescriptive instead of descriptive. The error is specifically saying ‚Äúbecause Paul talks about slaves \u0026amp; masters, that means that he is saying that slavery is good.‚Äù People in the (2) camp sometimes use this interpretation as reason to discredit Paul all together.\nMy interpretation# Approach (4) is a bit more complicated. So we start by acknowledging that the Roman world had slaves that may or may not have been treated well. It would probably be insane to try to completely dismantle this system both within or outside of the church at the time of writing.\nIn this context, Paul is saying that both slaves \u0026amp; masters can honor God within their roles. Slaves are called to be good workers for their masters, as this is ‚Äúserving the Lord‚Äù who will reward them. That‚Äôs an encouraging message, especially in the case where you‚Äôre forcefully working for a cruel and unreasonable master and don‚Äôt have any hope of escape or better work.\nMasters are exhorted to treat their slaves gently. ‚ÄúDo not threaten them, since you know that he who is both their Master and yours is in heaven‚Ä¶‚Äù This would have been disruptive at the time, putting masters and slaves on an equal footing with God. Also, Romans treated their slaves harshly. Just some brief searching (including the Wikipedia article I linked earlier) has examples of Roman slaves being whipped, branded, tattooed, and even crucified.\nTo zoom out even more, this passage is in a broader set of relational exhortations:\nEph 5: wives \u0026amp; husbands Eph 6: children \u0026amp; parents Eph 6: slaves \u0026amp; masters To be transparent, I‚Äôm an egalitarian, not just because I know it to be right, but also because of how I read these passages. However, that‚Äôs a rabbit hole that would be a post of its own.\nFirst, I want to call out the fact that (1) is separated from the other two with a chapter boundary is frustrating as it‚Äôs completely arbitrary (Paul did not write with chapter divisions) and it makes it harder to see the literary pattern.\nNext, you want to note that all of these relationships involve a power imbalance. Then, the pattern is clear that Paul first addresses the weaker group and tells them mostly to just keep doing what they‚Äôre doing cheerfully; by doing this, they honor God. This is because being humble and serving others is what Christians are called to do, so they are already in the correct posture.\nThe disruption is that Paul tells the powerful groups to respect the weaker groups:\nHusbands should cherish their wives as if they‚Äôre their own bodies, and feed and take care of them. Husbands should love their wives as Christ loves the church and should give up their lives for their wives ü´¢. Fathers shouldn‚Äôt provoke their children to anger. Masters shouldn‚Äôt threaten their slaves. When framed like this, it makes so much sense to me that Paul isn‚Äôt arguing for the status quo, nor is he propagating the Roman worldview on gender and slavery, but rather showing how people in these challenging situations as well as positions of power can still serve God as faithful followers.\nOk, so what?# So, what‚Äôs the takeaway? Whether you‚Äôre diving into biblical passages or any other historical text, reading with empathy for the author opens up a more nuanced understanding of the message. As modern readers, we‚Äôll inevitably bring our values into the text. But that tension - between what was written then and what we believe now - doesn\u0026rsquo;t have to be an obstacle. If we approach ancient writings with humility and curiosity, we just might learn something about both the past and ourselves.\nFurther ‚Äúreading‚Äù# I didn‚Äôt just get this lens from reading the Bible carefully. I‚Äôve listened a lot to the podcast My Strange Bible from Tim Mackie; this episode in particular was eye-opening for me on learning \u0026amp; applying this historical lens to the Genesis creation account. There‚Äôs also a bundle of other content on interpreting Paul correctly, but I‚Äôll save that for future posts when I talk more about gender \u0026amp; the Bible.\n","date":"2025-01-02","id":5,"permalink":"/posts/historical-texts-empathy/","summary":"Reading the Bible in an academic fashion has taught me a skill that has been extremely useful when reading other historical texts, but seems to be something that modern readers seem to be losing. I notice this especially when people struggle to read anything older than X year (e.g. 1960), because it has concepts that they fundamentally disagree with.\nI call it ‚Äúempathy for the author.‚Äù When reading a text and trying to understand it, my first goal is to try to learn as much about the author as possible and their worldview. Then, I attempt to understand the points they‚Äôre making. I think other people should do the same.\n","tags":["christianity","lemma"],"title":"Learning to read historical texts with empathy"},{"content":"Previous article: What I\u0026rsquo;m up to\nAbstract / Results# It feels a bit pretentious to open a blog post with an abstract. However, I wanted to communicate up front concisely what I tried to do, and what the open areas of exploration are. Those who are interested can dig more.\nI wanted to make ChatGPT into a magic decompiler for PowerPC assembly to supercharge the Super Smash Bros. Melee (\u0026ldquo;Melee\u0026rdquo;) decompilation project. I observed over a year ago that ChatGPT was surprisingly good at understanding PowerPC assembly language and generating C code that was logically equivalent. I also saw other papers that were attempting to use LLMs as decompilers.\nProblem statement: given the PowerPC ASM a1 of a function f1, use AI to come up with C code that compiles to a2 where a2 == a1 (note: the C code doesn\u0026rsquo;t have to be the same as the original. There are many C programs that map to the same assembly). This is called match-based decompilation, as merely being logically equivalent is not sufficient. Also, in the case where a2 isn\u0026rsquo;t a match, iteratively improve on the result.\ngpt-4o was able to often generate code that was logically similar. It was also able to iteratively correct compiler errors (even for an older dialect of C). However, it was unable to improve on its results even when given the assembly diffs in a digestible format. It showed understanding of the assembly diffs, but wasn\u0026rsquo;t able to actualize that into logical changes to the C code that brought it closer to its target. I also briefly investigated fine tuning and didn\u0026rsquo;t get results.\nThere are a couple of explorations left to be tried, but before I get into that, some notes about the problem space:\nThis isn\u0026rsquo;t a classic RLHF problem. You don\u0026rsquo;t need human feedback at all. Especially with the automated tooling I set up, you can actually automatically \u0026ldquo;score\u0026rdquo; how close the ASM is to the target ASM. So maybe a more classic RL approach would be interesting Coming up with C code that compiles to the same ASM isn\u0026rsquo;t actually all that\u0026rsquo;s needed for the decompilation project. This tool wouldn\u0026rsquo;t be powerful enough to wire in struct definitions from other parts of the codebase, or even handle imports. On the other hand, LLMs with retrieval could actually be pretty good at this, and tools here would be much appreciated to the scene What we\u0026rsquo;re trying to do# So we\u0026rsquo;re trying to write a magic-decompiler for Melee. You might ask, why do game decompilation? And why Melee? Valid questions!\nWhy Melee?# Simple. The game is dear to my heart even if I don\u0026rsquo;t play it that much anymore, and it\u0026rsquo;s still competitively alive today despite coming out in 2001. Also, people have already written extensive modifications for the game, and this would help both:\npower future modifications make it more accessible for new developers to join the fray Game Decompilation?# There have been a bunch of successful game decompilation projects in the last couple of years, which were then followed by some really cool modifications to the games. One of my favorite ones is adding raytracing to Super Mario 64 which adds beautiful accurate shadows, reflections, and global illumination. While I dream about adding raytracing to Melee, that probably wouldn\u0026rsquo;t be a great idea since input latency is almost always the top priority when playing the game, but mods like extensive UI modifications or model swaps are definitely fair game.\nNow, it\u0026rsquo;s going to get more technical. First, some background info!\nBackground info# Match-based decompilation# Game decompilation isn\u0026rsquo;t the same as normal decompilation that security engineers do with Ghidra. What we\u0026rsquo;re trying to do is called match-based decompilation.\nAssuming a game is written in the C programming language and we have the game binary (in whatever architecture the console is in. For the Gamecube, it\u0026rsquo;s PowerPC), we want to attempt to reconstruct C code that is similar to what the game developers wrote themselves.\nNote that I said similar and not identical. Compilation is inherently a lossy process, especially as you turn on optimization flags. Comments are almost always stripped out (so your // help me isn\u0026rsquo;t going to make it to prod üòã). However, there are some ways to slice similar.\nHere are two C programs, \\(C_1, C_2\\), that are logically similar:\n// Program 1 int main() { int i = 1; int sum = 0; while (i \u0026lt;= 5) { sum = sum + i; i = i + 1; } return sum; } // Program 2 int sum(int n) { if (n \u0026gt; 0) return n + sum(n - 1); return 0; } int main() { return sum(5); } These produce drastically different assemblies, \\(A_1, A_2\\), when we use the compiler \u0026amp; flags for Melee.\n# Program 1 00000000 \u0026lt;main\u0026gt;: li r3,15 blr # Program 2 00000000 \u0026lt;sum\u0026gt;: # impl of int sum(), 33 lines 00000088 \u0026lt;main\u0026gt;: mflr r0 li r3,2 stw r0,4(r1) stwu r1,-8(r1) bl 98 \u0026lt;main+0x10\u0026gt; addi r3,r3,12 lwz r0,12(r1) addi r1,r1,8 mtlr r0 blr The compiler completely inlines the logic for \\(C_1\\), in that it doesn\u0026rsquo;t even compute the sum - it just directly loads the result, 15, into r3, the return register. You can probably see now how compiling can be lossy - we\u0026rsquo;ve completely lost the logic inside of main(). However, for \\(C_2\\), it actually generates code for the generic method int sum and also does all of the heavy-lifting to call the function.\nWhile both C programs would be a valid decompilation in some spaces, \\(C_1\\) would fail to be a match decompilation if the assembly we were trying to match was \\(A_2\\). Specifically, C code that would yield a match is a subset of all C code that is logically equivalent to the target ASM. We have to go as far as register allocations being identical.\nHere\u0026rsquo;s a more insipid example of programs that are really really similar. Here is a C program that calculates the fibonacci sequence iteratively:\nint fibonacci(int n) { int temp; int i; int a = 0; int b = 1; if (n \u0026lt;= 0) { return 0; } else if (n == 1) { return 1; } for (i = 2; i \u0026lt;= n; ++i) { temp = a + b; a = b; b = temp; } return b; } I\u0026rsquo;ve compiled this program to assembly, and then loaded it into decomp.me. Now, if we swap the declarations for a and b:\n// Old int a = 0; int b = 1; // New (logically equivalent) int b = 1; int a = 0; we get the following ASM diff (while the registers are the same, the instructions are in a different order):\nThis is pretty rough; that means that variable declaration order matters even if it doesn\u0026rsquo;t affect execution. Also, while these are small errors, there are really strange ways to massage the C code in order to get the compiler to spit out some ASM; you\u0026rsquo;ll notice this especially when it\u0026rsquo;s code that triggers a compiler bug.\nNow you might reasonably ask, why do we want the exact same assembly? Some reasons that are non-exhaustive:\nWe want to be able to build the exact ROM of the game. This is the easiest way to verify that the game was completely decompiled, as verifying logical equivalence is non-trivial Some existing understanding / mods of the game being decompiled rely on the program being laid out the exact same way. Modifying this extensively will make those (albeit brittle) changes not work anymore File types# OBJ: This is the output of a compiler. It contains binary machine code that a computer can execute. This is not the readable ASM that we\u0026rsquo;re dealing with, but the binary encoding of it. Looks like gibberish when opened, with occasional strings like \u0026quot;Hello\u0026quot; You can see that this file says that it\u0026rsquo;s an ELF in the \u0026ldquo;header\u0026rdquo;, which is the object file type for PowerPC. ASM: This is a human-readable representation of the machine code. It\u0026rsquo;s a programming language to some extent, but much lower level than C. For PowerPC, you\u0026rsquo;ll see instructions like li r1 3. .fn f1, global stwu r1, -0x18(r1) add r0, r3, r4 stw r0, 0x10(r1) addi r3, r1, 0x10 addi r1, r1, 0x18 blr .endfn f1 C: This is C code, which is the closest to human-readable, and what we\u0026rsquo;re looking for int* f1(int x, int y) { int z = x + y; return \u0026amp;z; } Tools# Compiler: this converts C code to an OBJ. This is often a lossy process and the original C code cannot be recovered once you just have the OBJ file, especially as you turn on optimization flags. Decompiler: this would convert either OBJ or ASM -\u0026gt; C. For this particular project, a perfect decompiler doesn\u0026rsquo;t exist but we\u0026rsquo;re looking for something close. Disassembler: OBJ -\u0026gt; ASM. This takes a compiled object file and spits out a human-readable representation of the ASM. Sometimes, it\u0026rsquo;ll even add nice quality-of-life fixes such as changing register arguments from numbers to names like r1 or sp. Assembler: ASM -\u0026gt; OBJ. This converts from an ASM to an OBJ. I needed this specifically because the ASM differ I used, asm-differ actually best worked when comparing two object files (but the whole process takes in an ASM file as input). Specific tools to this project:\ndecomp.me: This is a batteries-included collaborative website where you can interactively \u0026amp; collaboratively decompile video games. It\u0026rsquo;s pretty crazy this exists. You barely have to understand how decompiling works to use this tool effectively; hell, I don\u0026rsquo;t think you even really need to know how to code. A lot of my project was understanding how decomp.me works internally. m2c (GitHub): This is the default decompiler used for decomp.me. It\u0026rsquo;s a great starting point for when you just have ASM, don\u0026rsquo;t get me wrong, but it: doesn\u0026rsquo;t produce code that compiles doesn\u0026rsquo;t really take matching into account mwcc: this is the MetroWerks C compiler. I\u0026rsquo;m specifically using a version that\u0026rsquo;s identical (or close to) the one that the Melee team used, with the same flags as well. dtk disasm (GitHub): The disassembler I used. This tool is used by the Melee decomp project, and the assembly in the GitHub follows the output format. powerpc-eabi-as: The assembler I used. asm-differ (GitHub): The ASM differ \u0026amp; scorer that decomp.me uses. Was pretty nontrivial to get working the same way. Both decomp.me and my project had to do some workarounds to call it conveniently. I\u0026rsquo;ll be referring to these formats / tools, so feel free to return to this section. I\u0026rsquo;ll also explain how to get some of these later.\nWhat did I do?# When I was in the prototyping phase, I was just giving ChatGPT a copy-and-pasted prompt and an assembly file and plugging in the C it gave me to decomp.me. While the code was impressive and usually a close logical match, the code often didn\u0026rsquo;t compile. mwcc uses a pretty old version of C which didn\u0026rsquo;t have a lot of the features we rely on today (e.g. you have to declare all of your variables at the beginning of a function!!), and I bet that didn\u0026rsquo;t make up a lot of ChatGPT\u0026rsquo;s training set.\nI then had a flashback to having crazy TypeScript errors and ChatGPT figuring out all of them at my last job. When I gave ChatGPT all of the compiler errors I had for a given C program, it was really good at fixing the problems without changing the code too much! It would usually take one or two tries to get it to compile, but when actually checking the match score, it wasn\u0026rsquo;t close to a match.\nI realized that the iterative process that I did to get the code to compile could be something to automate. And not just that, I could apply this loop-improvement cycle for ASM matching. But I was pretty far from this: I was currently just holding a bundle of ASM \u0026amp; C files, and copying and pasting them into decomp.me. Getting the ASM from a given C program was hard for me at that time: I even wrote a script to parse the compilation results from decomp.me\u0026rsquo;s backend üò≠ since I couldn\u0026rsquo;t figure out how to go from C -\u0026gt; OBJ -\u0026gt; ASM. In order to automate this whole process, I\u0026rsquo;d have to figure out how to run all of these things locally. Specifically:\nCompiling C code with mwcc Comparing ASM files \u0026amp; scoring them Writing a state machine that loops and either fixes compiler errors or attempts to improve the ASM match At this point of time, I hadn\u0026rsquo;t verified if ChatGPT was capable of improving the ASM score. It was too difficult to hold onto all these C files and get them to compile while juggling around a bunch of prompts.\nCompiling locally# The objective here is to be able to take a small C function, f1, and get the resulting ASM, ideally in the same format as the Melee codebase.\nFirst, we have to start by getting the binaries! It took me a while to figure this out, but the Melee codebase has a helper tool to download a lot of the common binaries. You can just run:\nninja build/binutils This will download a bunch of tools including the assembler we\u0026rsquo;ll be using. You also might just want to run ninja to download the rest of the tools, as we\u0026rsquo;ll also need to download\ndtk the compiler. This ends up being in build/compilers Once I got these binaries, I realized that some of them (namely, the compiler) are Windows programs. As I am developing on a Mac, it took some tinkering to get the compiler to work using wine. My invocation ended up looking something like this (I got the args from decomp.me):\nwine bin/mwcceppc.exe -Cpp_exceptions off -proc gekko -fp hard -fp_contract on -O4,p -enum int -nodefaults -inline auto -c -o temp.o FILENAME Once I had my .o files (OBJ), to get the ASM, you have to run it through a disassembler. I ended up calling that like this:\n../melee/build/tools/dtk elf disasm outputs/temp.o temp.s So the whole compilation flow looks something like this:\nChatGPT generates a toy C program We run it through the compiler, mwcc, to get an OBJ file We then run the OBJ file through a disassembler, dtk disasm, to get an assembly file, .s Comparing ASM files and scoring them# Now that we got ASM output, we want to be able to compare two ASM files. You could do something as simple as diff the two .s files. However, I noticed that decomp.me had a much more sophisticated differ, that also included scoring. I\u0026rsquo;ve shown screenshots earlier, but here\u0026rsquo;s a more complicated example:\nAlso, check out the insanity on line 50. There are TWO b 90s. b is just an unconditional jump, which means that line 54 should be unreachable. There are a lot of nice features here:\nscores. both % match as well as a number that decreases -\u0026gt; 0 as you get closer. same as diff: lines missing or additional lines register errors, marked with r not shown, but immediate errors are marked with i I had already tried giving ChatGPT simple diff outputs to see if it could improve the matches, and didn\u0026rsquo;t succeed, so I hoped that giving it a richer picture of the diff would improve its output.\nI ended up going on a deep dive to see how decomp.me accomplished their rich ASM diff view. After some trudging through the codebase, I found where the magic happens: this file wraps a library called asm-differ (GitHub).\nAt first, I was excited to find out that it was a library already by itself. However, the library isn\u0026rsquo;t super easy to call for a one-off situation: it\u0026rsquo;s meant to be used with a C project. I did go through the pains of configuring it properly to make sure it\u0026rsquo;s output was what I was looking for first. Then, I ended up doing something similar to what decomp.me did - write a wrapper program that calls into internal methods of asm-differ and manufactures a project config in-memory. Here\u0026rsquo;s where I did that, and here\u0026rsquo;s where decomp.me did it. My implementation is a little janky as it definitely expects some files to be in the right places, but more on that later. The ASM diff ends up being almost exactly like the website\u0026rsquo;s, which is a huge win! üéä\nThe state machine# I didn\u0026rsquo;t realize that this was a state machine at first. I went into this portion of the project like \u0026ldquo;I need to call ChatGPT in a loop, and I need to glue all of these tools together.\u0026rdquo; I was just copying and pasting long bash commands and pasting inputs and outputs into ChatGPT, and so testing many examples at scale was just not feasible.\nThere are two processes at play here:\nFix errors: Given a C program that doesn\u0026rsquo;t compile, fix it while keeping the logic the same Improve ASM score: Given a C program that does compile but doesn\u0026rsquo;t match, try to improve the matching score. When asking ChatGPT for C code, the initial state looked like this:\nFixing errors was pretty simple. We just compile the program, get the errors, and then ask ChatGPT to attempt to fix the errors. I initially tried to get ChatGPT to fix the errors by just pasting in the last compile run\u0026rsquo;s errors. This generally took around 5 passes to get code that compiled. A simple improvement was to send all of ChatGPT\u0026rsquo;s attempts in a chain from the last success, which then got it down to 1-2 passes. Once we get C code that compiles, we transition to (2):\nNotably, I didn\u0026rsquo;t include all the errors that ever happened. This process anchors off of the last transition from compiler success -\u0026gt; failure, or the initial C code returned from ChatGPT, as I didn\u0026rsquo;t want to blow up the context window. You\u0026rsquo;ll see this as a common theme. The candidate phase is a bit more interesting and actually tests the hypothesis. From a high level, we want to compare the assemblies of the C code we have and the assembly target, get a diff that is easy-to-interpret, and ask ChatGPT to attempt to improve the C code to be a closer match.\nWe start with a candidate, \\(C_1\\):\nWe first need to get the ASM after compiling \\(C_1\\). We compile the program to get an OBJ file, c1.o, and then we run it through dtk disasm to get ASM \\(A_1\\). Then we have to diff \\(A_1\\) and \\(A_T\\). We use asm-differ to get both a score \u0026amp; a line-by-line diff. Let\u0026rsquo;s call this \\(D_1\\). Then, given \\(C_1\\), the score, and \\(D_1\\) (which contains both \\(A_1\\) and \\(A_T\\)), we ask ChatGPT to generate a new candidate that is a closer match. We get \\(C_2\\). Now, if you\u0026rsquo;ve been following along, you can probably tell that this is going to be a loop of some kind:\nThere\u0026rsquo;s a subtle difference with the list of candidates. This is a global list instead of local to the state, as we always pass in all of the successful candidates to ChatGPT. The error list resets every time we have a new code example to anchor on. Ultimately, the functionality of this program was to improve the ASM score, so I disregarded blowing up the context window for this phase since I hoped having more information would improve the loop\u0026rsquo;s result. Also, the error fixing loop actually terminated pretty quickly, so keeping track of all the \\((c_x, e_x)\\) pairs was unnecessary.\nTesting# Now that the improvement loop was finished, it was time to run it! But before that, we need some input datasets.\nTraining set# The nice thing about creating a list of inputs and expected outputs is that it doubles as a training set. After doing so many manual tests, I already had an inclination that results wouldn\u0026rsquo;t be good without fine tuning.\nI came up with a small training set for mwcc here. The repo is separated into 10 /general examples and 3 /melee examples. You might ask: why make so many general examples if you\u0026rsquo;re trying to decompile Melee?\nThe reason why is that even though we have C / ASM pairs in the Melee decompilation codebase, the code is really idiomatic aka it requires a really large set of headers / context to compile a given function. This poses the following issues:\nIf we were to paste in all the context required to compile the function, it will easily exceed 4o\u0026rsquo;s token length (I did verify this myself) Conjecture: Any fine tuning might not generalize to different functions that have unknown structs, so making it more generic would give the model a higher likelihood of generalizing General examples were probably good enough. We wanted ChatGPT to learn the compiler\u0026rsquo;s behavior with a set of flags. Coming up with general examples was so easy:\nAsk ChatGPT to generate a toy C program with no includes, probably on a problem I\u0026rsquo;m familiar with (e.g. reversing a linked list) Get the code to compile. You can even ask ChatGPT to fix the errors Disassemble it to get the resulting ASM Save it as a C ASM pair Coming up with Melee examples was harder. I essentially had to find really small functions, or attempt to rip out all the context from an already-solved portion of the Melee codebase. That means not using any structs, attempting to be closer to the ASM than even the solution, etc. It wasn\u0026rsquo;t a pleasant process and I couldn\u0026rsquo;t figure out how to automate it.\nActually testing# I ran most of the general code examples through the whole loop. The results weren\u0026rsquo;t great. ChatGPT:\n‚úÖ was able to fix compiler errors ‚úÖ seemed to understand the ASM diffs and was able to identify issues ‚úÖ was able to generate C code that logically was pretty similar or identical to the ASM ‚ùå was not able to substantially improve the match score. I tried this on a bunch of different code examples. Here\u0026rsquo;s a graph of one of the longer runs:\nThis doesn\u0026rsquo;t include the compiler error fix passes. The score generally doesn\u0026rsquo;t improve and kind of fluctuates about its starting point. I was able to reproduce a lack of improvement on many different code examples \u0026amp; runs. 20 passes was around where I started running out of context window as the asm-differ output was pretty long.\nSo at this point I decided that the hypothesis was false for the out-of-box model. But we\u0026rsquo;re not done!\nFine tuning# I didn\u0026rsquo;t really go that deep in on fine-tuning. I was mostly curious about the flow for gpt-4o and if this would be a potential magic bullet.\nI already had examples in a Q\u0026amp;A format. The OpenAI docs generally recommended to use 4o-mini if your task was already doable with 4o and you wanted to do it for cheaper after fine tuning. As I knew that the task wasn\u0026rsquo;t doable with 4o, I ended up opting for fine-tuning 4o.\nThe fine tuning UI was broken which was sad (I filed a ticket), but then I just curled their backend to start the fine-tuning job. $21 later, I realized that I didn\u0026rsquo;t have the money to keep doing this LOL. I did get a pretty graph:\nThe really low training loss was interesting to me. I spent some time testing the fine-tuned model. My observations:\nThe fine-tuned model basically memorized the training examples. Given the exact same prompt, it would spit out C code that had a really low score of like 20, which is an over 99% match. However, varying the TEXT in the prompt (not the ASM) would make the match much worse, which sucked It didn\u0026rsquo;t generalize outside of the training set. Performance for ASM it hasn\u0026rsquo;t seen before remained at roughly the same thresholds with no improvement after additional passes. I was hoping that fine-tuning the model would help it extrapolate to the \u0026ldquo;C that mwcc would compile to a given ASM.\u0026rdquo; It did not do that, and it also didn\u0026rsquo;t even figure out what type of C code would more easily compile with mwcc (e.g. it still required multiple passes to get compilable code) üò•.\nConclusion# I really enjoyed this project as my first serious AI project. If I didn\u0026rsquo;t try it, I would have gone insane: the first time over a year ago I saw ChatGPT spit out C code after looking at some assembly, I was haunted by what could be if AI was actually a magic decompiler. My inner demons were arguing about the ethics of solving this problem, but they got ahead of the actual reality:\nAI isn\u0026rsquo;t a magic decompiler. But that doesn\u0026rsquo;t need to be the end of the story. On my GitHub for this project, I\u0026rsquo;ve detailed some alternate explorations that could be really fruitful, but I just ran out of time (or money). The problem statement is still compelling enough to me that I might work on it in the future.\nThanks for reading! Now I\u0026rsquo;ll probably go look for a job :)\n","date":"2024-12-10","id":6,"permalink":"/posts/chatgpt-not-compiler/","summary":"Previous article: What I\u0026rsquo;m up to\nAbstract / Results# It feels a bit pretentious to open a blog post with an abstract. However, I wanted to communicate up front concisely what I tried to do, and what the open areas of exploration are. Those who are interested can dig more.\nI wanted to make ChatGPT into a magic decompiler for PowerPC assembly to supercharge the Super Smash Bros. Melee (\u0026ldquo;Melee\u0026rdquo;) decompilation project. I observed over a year ago that ChatGPT was surprisingly good at understanding PowerPC assembly language and generating C code that was logically equivalent. I also saw other papers that were attempting to use LLMs as decompilers.\n","tags":["tech"],"title":"ChatGPT isn't a decompiler... yet"},{"content":"A lot of people have been asking what I\u0026rsquo;ve been up to since I left Plaid at the beginning of this month. I was at Plaid for 4 years, which were amazing and I am very thankful for the amazing people I\u0026rsquo;ve met and work I\u0026rsquo;ve been able to do.\nI am not funemployed, and I don\u0026rsquo;t want to evoke concepts related to that. I\u0026rsquo;m grinding harder than I did while employed. It\u0026rsquo;s such a gift to be able to have software engineering skills that have been forged in a real tech company, and then let loose on personal projects. I\u0026rsquo;m working on learning as much as I can about the AI space and debating if I should make that my next 4-year move. AI has been moving faster and faster, and there are so many toy projects I want to build:\nAlready built this, but my Notion AI autotagger Deepfaking my own voice and using it to read ebooks out loud - hopefully deepfaking my own voice would bypass ethical constraints? Running LLMs on my own hardware A Biblical RAG Learning about the tradeoffs of RAGs in general, plus the cheapest arch to roll one out But I don\u0026rsquo;t want to just build toy projects. Specifically, I want to build an AI decompiler. I have done a little bit of work in the game decompilation space for Super Smash Bros. Melee, a video game that\u0026rsquo;s dear to my heart. If you want to know more about the general space, this doc that I\u0026rsquo;ve contributed to is a good place to get started. Last year when GPT-4 came out, I had a pretty strong feeling that LLMs would be great as a decompiler assistant, and I dreamt about having the time to investigate this more thoroughly.\nAfter some preliminary testing, it\u0026rsquo;s not amazing out-of-the-box. I got some decent results on the general model that get anywhere from 60% - 90% of the way there, but it seems that video game decompilation is both:\nvery specific to the compiler used, its flags, and just generally niche and probably not in the training data different from even normal decompilation, as video game decompilation is what we call \u0026ldquo;match decompilation\u0026rdquo; - I might write more about this in the future and its tradeoffs If the LLM approach doesn\u0026rsquo;t work, I\u0026rsquo;ll probably investigate some other spikes before washing my hands and writing a nice public postmortem, but yeah, this is what I\u0026rsquo;ve been spending my time on!\nI also spun up this site after I left my job, as Medium \u0026amp; Substack just weren\u0026rsquo;t cutting it for me.\n","date":"2024-09-23","id":7,"permalink":"/posts/what-i-have-been-up-to/","summary":"A lot of people have been asking what I\u0026rsquo;ve been up to since I left Plaid at the beginning of this month. I was at Plaid for 4 years, which were amazing and I am very thankful for the amazing people I\u0026rsquo;ve met and work I\u0026rsquo;ve been able to do.\nI am not funemployed, and I don\u0026rsquo;t want to evoke concepts related to that. I\u0026rsquo;m grinding harder than I did while employed. It\u0026rsquo;s such a gift to be able to have software engineering skills that have been forged in a real tech company, and then let loose on personal projects. I\u0026rsquo;m working on learning as much as I can about the AI space and debating if I should make that my next 4-year move. AI has been moving faster and faster, and there are so many toy projects I want to build:\n","tags":["tech"],"title":"What I'm up to"},{"content":"In my journey as a blogger, I‚Äôve published posts across platforms like Medium, Substack, and other proprietary blogging stacks. When writing more and more technical stuff, I realized that some stacks were definitely better than others.\nWhen consuming other people\u0026rsquo;s blog posts, the first thing that stood out to me was aesthetics. You get an impression about the platform and the person simply by the details of how their text looks. Does their code have great, language-specific highlights? Do they use monospace + does their platform support it? How is the image formatting? What about the base color scheme?\nAs I worked with more platforms, I became frustrated with how my posts looked different on varying sites. The aesthetics were just too divergent, and I couldn\u0026rsquo;t exactly express what I was writing in my Notion. My brain also noticed that there was an inverse correlation with \u0026ldquo;how cracked someone was\u0026rdquo; and their propensity to using Substack or Medium. I realized that it was time for change.\nSo, when designing something / researching what\u0026rsquo;s out there, the first exercise is to list out your requirements:\nFeature-set that I want# I mostly listed out these nice-to-haves in a blogging platform:\nMarkdown-driven. The format that I actually draft posts in + how I research things are in markdown-driven platforms (like Obsidian!), so it would be nice for the posts to be very similar Arbitrary code highlighting. Ideally I would like to just support every language I write, but sometimes the project I\u0026rsquo;m going to do will be niche enough that that would be a high expectation. I\u0026rsquo;m going to write a post soon on decompiling PowerPC assembly, and I doubt there\u0026rsquo;s an out-of-the-box solution View count per article. I like to see how popular different posts are. I also often post my blogposts on other platforms such as Reddit + X, and it\u0026rsquo;s nice to know how much traffic comes from there vs. direct links. Categorization. I had separate blogs for writing about Christianity \u0026amp; tech. The problem with this approach was that I actually wanted to write about more than just those two, but I didn\u0026rsquo;t really have a place to do that. But Medium and Substack seemed like you were supposed to focus on one specific topic rather than just a personal blog. So I wanted to have a place where I could write anything, and then just let people filter by the topic they\u0026rsquo;re interested in. Some other topics I wanted to write about were cocktails, food, video games, and more! Minimal upkeep. If I have to host the thing, I\u0026rsquo;d like to not have to spend any time configuring the website \u0026amp; it should just work. Inline \\(\\LaTeX\\) support. Substack added block LaTeX support, which is nice, but wasn\u0026rsquo;t exactly what I was looking for. Notion has inline LaTeX support which flows really nicely and allows you to just use it as an extended vocabulary while writing a paragraph. Nested bullets. You\u0026rsquo;d be surprised that Medium doesn\u0026rsquo;t support nested bullets. I had to do this silly workaround, and it only works up to two levels. WTF??? My stack + how it addresses my requirements# After some investigation, I realized that there\u0026rsquo;s a whole plethora of solutions around markdown driven-blogs. I found hugo as well as a beautiful theme for it called gruvbox (which also happens to be the theme that I use for emacs!).\nhugo gruvbox Sometimes, when you first express your requirements and see what\u0026rsquo;s out there, you realize that people are beautiful and have often thought much more deeply about the problem you\u0026rsquo;re trying to solve than you could have ever imagined. Hugo often felt this way. They\u0026rsquo;ve done a great job expressing the problem of markdown files -\u0026gt; static site and have added all types of enhancements on top of markdown! It\u0026rsquo;s also very easy to add things like inline \\(LaTeX\\). The categorization problem I was talking about they\u0026rsquo;ve solved with taxonomies, which are honestly way more in-depth than what I needed; I can just solve my issue with using one of their default taxonomy, tags.\nI was able to address all of my feature requests easily with hugo with one exception: view count per-blog-post. I could integrate Google Analytics, but the numbers may be skewed by adblockers. I also wouldn‚Äôt know where readers came from. But does that really matter? What I truly value is the discussion sparked by my posts, not just the view count.\nThis stack however is not a one-size-fits-all recommendation for bloggers. I definitely pulled out my hair a bit figuring out how to configure hugo with the theme, and I don\u0026rsquo;t think using GitHub pages is viable for anyone who is non-technical. But, then again, most of the features I care about only matter to technical people \u0026ndash; Medium \u0026amp; Substack should be good for most other use cases.\n","date":"2024-09-14","id":8,"permalink":"/posts/blogging-platform/","summary":"In my journey as a blogger, I‚Äôve published posts across platforms like Medium, Substack, and other proprietary blogging stacks. When writing more and more technical stuff, I realized that some stacks were definitely better than others.\nWhen consuming other people\u0026rsquo;s blog posts, the first thing that stood out to me was aesthetics. You get an impression about the platform and the person simply by the details of how their text looks. Does their code have great, language-specific highlights? Do they use monospace + does their platform support it? How is the image formatting? What about the base color scheme?\n","tags":["tech","meta"],"title":"Choosing a Blogging Platform: Aesthetic and Technical Considerations"},{"content":"Originally posted on Medium.\nI built the thing I talk about in this blog post ‚Äî if you want to check it out, it‚Äôs here!\nNotion, like every tech company, has been shoving AI features down our throats for the last couple of months at the cost of customer UX. So I disabled them. You can do this yourself by just messaging support ‚Äî I got the idea from this Reddit thread, which is one of many. Ever since I disabled it, the UX has at least returned-to-normal, and performance of editing has increased (have you ever noticed how Notion lags a bit every time you press SPC so that it can show you the AI toolbar?).\nAs I‚Äôm about to enter a brief phase of unemployment and grinding on personal projects, I‚Äôm looking for quick AI projects to whet my appetite to build. It turns out that some of Notion‚Äôs AI features were so simple that they‚Äôre great intro projects. Specifically, I was intrigued with building auto-labeling for my journal entries. Notion has a feature that, for a given database, you can label it with tags; on top of that, it has an AI feature that will read through all your entries and auto tag them:\nSo I‚Äôm already a paying customer for Notion. But they have the gall to charge me an additional $8/m to support this feature? Absolutely ridiculous! They already charge me $4/m simply to host my data and barely iterate on the product. To break this down on why this is ridiculous:\nThey already have margins from me paying to use Notion. Them adding these AI features on for free would be compelling customer-lock-in This feature can be implemented within a week by a disgruntled software engineer (me! it‚Äôs me!). Sure, I know, it‚Äôs not exactly the full scope of the things that feature offers (I‚Äôm guessing they have an async job kicked off when you make edits?), but it‚Äôs good enough for my purposes. In reality, using the API for GPT 4o is likely much cheaper than $8/m. Also, back when I had this feature on, they hadn‚Äôt even migrated to using the later GPT models. ü§Æ The project# The idea behind this is a great use of AI! Especially for my journal, I want to have the barrier of entry to write a journal entry (hehe) as low as possible, and keeping up the effort to manually tag every entry is a pain.\nWith the release of OpenAI‚Äôs structured outputs that guarantee that it returns something within your schema (aka the tags that you want), it‚Äôs very easy to guarantee that the AI output is just a list of tags.\nAs of right now, I have 451 journal entries that go back all the way to 2016 (yes, the start of reflective Stephen). Roughly 90 of them were tagged. And due to my journal being mostly organic growth, sometimes the tags that I used changed over time, and so they weren‚Äôt a consistent way to search through my journal.\nDesign# I knew that I had to do the following:\nUsing the Notion API: Pull the content for all my journal entries Using the OpenAI API: Feed the content into 4o and ask it what it would label the entry Using the Notion API: Overwrite the entry‚Äôs tags with the new generated tags Since this involves a lot of phases and any one of them can fail, I separated the scripts‚Äô running into four phases after learning the basics of the Notion API:\nGet all the pageIDs in the database (my journal) For each pageID, get the content Ask ChatGPT given the content \u0026amp; title \u0026amp; some more stuff what tag(s) the entry should have Actually write these tags to Notion ‚Ä¶and then built in support for snapshotting after each phase ran. The python script saves all of the results locally using pickle, which is something that works great in dev, but would not recommend using in production (my friends have horror stories!).\nTo actually get OpenAI to tag my posts well, I had to experiment with prompting, which leads to our next section.\nPrompting# This project is the wake-up call I needed to discover how important prompting is. At first, I thought I could just copy and paste my journal entry into ChatGPT and hope for some good tags. I hoped wrong, here are some of the issues I ran into:\nobviously, i needed to make sure that the AI only returned tags. You can‚Äôt do this via the web interface the AI was pretty tag-happy and added tags at a whim, when I really didn‚Äôt think it should tag it with that there wasn‚Äôt a way to pass in additional context, such as ‚ÄúX is my brother.‚Äù First, we want to use the structured outputs feature from OpenAI to make sure it only returns tags, and we can use them in code. That was easy enough, but I had to learn how the schema format works.\nAfter that, I discovered that there is a level of knowledge required about my life that are not easy for the AI to understand just from my entries. For example, how is the AI supposed to know the name of my brother? Girlfriend? Church? What school I went to? I realized that I would have to give it more information than just the entry, and also would have to make sure that the additional context doesn‚Äôt bleed into its tagging decision (just because I talked about my brother in the context doesn‚Äôt mean that he‚Äôs in the journal entry). There are three things we can modify: the system prompt, the schema, and the user prompt. Normally, on https://chatgpt.com/, you can only modify the user prompt. So I ended up coming up with this solution.\nIn the system prompt (context for how the AI should behave):\nYou are an AI assistant that labels content with appropriate tags. Please analyze the given title and content and assign relevant tags from the provided list. Be conservative in your tag selection: - Only assign tags if there\u0026#39;s a medium to strong correlation with the title and content. - It\u0026#39;s better to assign fewer tags or even no tags than to assign irrelevant ones. - Consider the context and overall theme of the content, not just keyword matches. - If you\u0026#39;re unsure about a tag, it\u0026#39;s better to omit it. Additional context to help understand the entries: {additional_context} The additional_context variable is simply an envvar that has things like \u0026ldquo;x is my church\u0026rdquo;.\nThen, in the user prompt, I passed it the title, content, and a reminder to tag the entry and be cautious about tagging.\nFrom a high-level:\nsystem prompt:DirectivesAdditional Context user prompt:TitleContentSome directives additional fields:schema: [ENUM TAGS] ‚Äî this makes sure that OpenAI uses your custom list of tags, and only returns those. Methodology# There‚Äôs been a lot of hype around Cursor, the AI-powered fork of VSCode. I‚Äôm a committed user of Emacs, but my integration with ChatGPT has been getting a little stale as gptel is pretty bare-bones (it is possible I have not been keeping up with its new features). I decided to try it out for this project and then later, attempt to fold in these UX features into Emacs.\nCursor is amazing. I barely wrote any code for this project myself. I often just selected the whole file, pressed CMD + K, and told it to add x feature.\nThis doesn‚Äôt mean non-technicals can build fully-fledged apps on their own with Cursor. I was very specific with my requirements, and I understood thoroughly how this project would work down to the checkpointing feature. I just didn‚Äôt want to take the time to learn Notion‚Äôs API. On top of that, OpenAI‚Äôs new structured output feature is brand-new, so there‚Äôs no way that Claude 3.5 Sonnet would have known about it.\nI also wrote a couple of scripts that helped debug this project as I ran it over and over. The most helpful script allows you to run all 4 phases on just one page within the database, so if you end up trying this project yourself, check out scripts.py.\nClosing thoughts# There are probably features that Notion could build that reasonably use their customer-lock-in. If they made a RAG on all of my workspace, that would be sick. Or if I could figure out all the things I‚Äôve said about git! They could build an amazing search that also processes your attached images, and runs OCR on them, and/or uses location information to be like \u0026ldquo;what in my workspace is about Paris?\u0026rdquo; But I don\u0026rsquo;t have a lot of faith considering that their current search is abysmal, and I\u0026rsquo;ve just been disappointed time and time again with their roadmap.\nI‚Äôm kind of soft-evaluating Notion alternatives, but it‚Äôs been hard to figure out exactly what my requirements are. Offline mode is important, but also I want to be able to share my documents, I want them to look pretty, I want nice looking code blocks, I want features beyond basic markdown ones‚Ä¶. it‚Äôs hard to find all of these. Also, lowkey, it would be cool to have a platform for my blogs that isn‚Äôt Medium or Substack. My search continues‚Ä¶\nFor now, though, I‚Äôll be using this tagger to help auto-tag my entries and rediscover my old entries all over again. It‚Äôs always funny to find an entry that‚Äôs titled ‚ÄúI can‚Äôt do this anymore‚Äù and see the tag Dating üòÖ. If you want to use this and are struggling with my GitHub, feel free to open an issue or write a comment here! Onto my next project :)\n","date":"2024-09-04","id":9,"permalink":"/posts/notion-ai/","summary":"Originally posted on Medium.\nI built the thing I talk about in this blog post ‚Äî if you want to check it out, it‚Äôs here!\nNotion, like every tech company, has been shoving AI features down our throats for the last couple of months at the cost of customer UX. So I disabled them. You can do this yourself by just messaging support ‚Äî I got the idea from this Reddit thread, which is one of many. Ever since I disabled it, the UX has at least returned-to-normal, and performance of editing has increased (have you ever noticed how Notion lags a bit every time you press SPC so that it can show you the AI toolbar?).\n","tags":["tech"],"title":"Why pay for Notion‚Äôs AI? I built my own auto-tagging tool in a week!"},{"content":"Originally posted on Substack.\nBrief doc I\u0026rsquo;m sending to my friendos\nFor transparency, I‚Äôm going to recommend a paid window switcher I use for Mac OS X called Contexts. It‚Äôs saved me so much time and has made using my computer a breeze; so much so, that I‚Äôve bound it to CMD+Tab. I‚Äôll attempt to justify this in the doc.\nThe default window management paradigm in Mac OS X, for me, left much to be desired. I grew up using Windows, which has a pretty different pattern for how you Alt+Tab between windows.\nIn Mac OS X, when you CMD+TAB, you can switch between apps; however, if you want to specify within windows of the same app, you‚Äôll have to issue another command: `CMD+`` lets you switch between windows of the same app. So you often have to issue multiple commands to get to the right window, which doesn‚Äôt even address that you often have to cycle a lot to get the app that you‚Äôre looking for.\nAs I‚Äôm a huge proponent of operating my computer with my keyboard as much as possible, you can get to the right ‚Äúapp‚Äù at least by using spotlight instead of CMD+Tab. You do CMD+SPC which pulls up Spotlight, and then you type in ‚ÄúChrome‚Äù or ‚ÄúChr‚Äù and then press enter. This solves the scrolling problem for CMD+Tab. However, we still have the issue of getting the right window focused.\nI personally prefer the Windows paradigm of treating every window as unique, rather than grouping them by app. So, after investigating a bit, I found an app that does exactly that!\nEnter Contexts# https://contexts.co/\nContexts doesn‚Äôt just disambiguate between different windows of the same app, but it also lets you search for the window with a prefix of its title. So I can type in Hold(CMD+TAB)+Sla and I‚Äôll get Slack really quickly. Faster than I could scroll to it.\nAlso, if you have two chrome windows with one with calendar and the other with some other pages, you can just type in Cal into the window and it‚Äôll pull up.\nIt has a free trial! Try it out üôÇ.\n","date":"2024-03-22","id":10,"permalink":"/posts/window-management/","summary":"Originally posted on Substack.\nBrief doc I\u0026rsquo;m sending to my friendos\nFor transparency, I‚Äôm going to recommend a paid window switcher I use for Mac OS X called Contexts. It‚Äôs saved me so much time and has made using my computer a breeze; so much so, that I‚Äôve bound it to CMD+Tab. I‚Äôll attempt to justify this in the doc.\nThe default window management paradigm in Mac OS X, for me, left much to be desired. I grew up using Windows, which has a pretty different pattern for how you Alt+Tab between windows.\n","tags":["tech"],"title":"How I do window management in Mac OS X"},{"content":"Originally posted on Substack.\nTry it out here if you like pressing buttons as much as I do! GitHub if you like reading code.\nDuring the holidays, I wanted to get better at answering questions like ‚Äúwhat is 7 half steps up from A?1‚Äù I often found myself in the situation of having these problems as a lot of guitar chord sheets are written something like ‚ÄúA capo 7‚Äù which means you put the big barre thing on your guitar and play an A-shape chord. When using a capo, the actual underlying chord is \u0026lsquo;A + 7 half steps\u0026rsquo;. This means if you\u0026rsquo;re collaborating with another instrument or with someone not using a capo, you need to communicate the actual chord you\u0026rsquo;re playing. This requires some mental math, which I found slightly embarrassing as I didn\u0026rsquo;t always immediately know what chord I was playing.\nI had an idea that if I had a program ask me a ton of these questions, my brain would develop some type of internal algorithm to answer the question. And‚Ä¶ spoiler alert, it did! Though we‚Äôll talk about that later.\nWhat / how to build?# Making a program that calculates intervals and randomly picks notes isn‚Äôt that difficult. However, I did make a couple of decisions on how to build the app based on some goals + non-goals:\nGoals# To be able to use the app both on my computer and phone. Phone mostly because I‚Äôd use it at the gym. Fast iteration speed plus once I was done to put a bow on it. I have a lotof personal projects that are just in semi-limbo and I was tired of notfinishing things. Look ok to nice Non-goal: storing state. Didn‚Äôt have a lot of upside for the upfront + maintenance complexity These goals pushed me heavily into making some type of web app despite my disdain for JavaScript. I also limited the feature set to a simple quiz, which asks you to identify the next note based on a random note and half-step interval.\nSince I wanted to really go fast, I didn‚Äôt want to spend time struggling with TypeScript compilation errors. My stack ended up looking like this:\nJavascript x React with create-react-app Deploying via Vercel No backend I focused first on building the underlying interval calculation, which I overly complicated for myself as I focused on enharmonics too early. For those who don‚Äôt know, enharmonics are different ways of writing the same note (e.g. A‚ôØ/B‚ô≠)2. After maybe an hour, I had a program that looked like this and worked:\nEnter ChatGPT# I\u0026rsquo;m not a fan of CSS, and even though it has improved over time, I never took an interest in mastering it. So as GPT4 now accepts images, I was like ‚Äúwhy not just ask it to make it look better?‚Äù\nPrompting is usually a bit of a magic art, but in this case, I was pretty straightforward:\nand after a couple of corrections, and some screenshots of bugs it had introduced, I had this!\nIt was so much better than something I would have come up with by myself. And once I had this screen presented to me, I had a couple of straightforward suggestions which then made the final product. Also, making the app look nice and adding visual feedback to correct \u0026amp; incorrect answers made me a lot more motivated to play the game, which was great.\nI basically made it so that CSS was 100% ChatGPT‚Äôs arena, and the React components were ‚Äúallowed to be refactored‚Äù; the core logic I did not allow ChatGPT to modify. I‚Äôm glad I kept this abstraction barrier, as ChatGPT often removed features or introduced slight logic bugs when I allowed it to just rewrite the components. Some examples:\nIt nuked the feature I wrote in to message what the correct note should have been if you get it wrong It didn‚Äôt notice my bug and sometimes made it worse that displayed different enharmonics on rerenders, since it depends on Math.random() It would highlight the right answer on errors, but then fail to do that on successes which was confusing üí° There‚Äôs always a disparity between expressing the problem statement in language ‚Üí actually solving the problem. The gap between precisely expressing the problem and solving the note interval solver was super small for me; however, for expressing how the app should look + how to implement it in CSS, I was mostly at an impasse and only had vague sketches in my head. ChatGPT‚Äôs raw velocity was absolutely insane for me.\nHow my brain got better at this# I‚Äôve only spent maybe like 30 minutes actually using the tool, but I‚Äôve already gotten so much better at the problem! Let‚Äôs go back to the original problem of ‚Äú7 half steps up from A.‚Äù How my brain solves it is:\nConverts 7 half steps ‚Üí perfect 5th up Imagines a violin and goes up a string, and sees E Unfortunately (2) is pretty specific for me, as I‚Äôve played violin since I was 8 or 9. But you can re-arrange this to:\nConvert half steps to a music interval, like ‚Äúminor 6th‚Äù Go from interval to note Which is pretty reasonable. Also, (2) is pretty valuable in itself as a musical skill üòä.\nConclusion# I‚Äôve been programming for a while. One thing they don‚Äôt tell you in school is that when you get better at making personal projects + fast iteration, you get better at solving your own (technical) problems. Sure, your first personal project might not be worth it on the ‚Äúeffort invested vs. time saved‚Äù curve; however, if you get really good at making programs that solve your problems, you‚Äôll start to find that it swings really far in the other direction.\n‚Ä¶of course, writing this article definitely took more of my time but ü§∑‚Äç‚ôÇÔ∏è. I also kind of enjoy doing this type of thing so it‚Äôs still worth it for me.\nWe are also in such a golden age of creating really fast apps and deploying them as tooling is so good. Like I legit just launched a website with my app on it for free. Go Vercel!\nit‚Äôs E\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nyes I know that these are different notes depending on if a temperament is assumed. this is another reason why I cut scope and didn‚Äôt do music intervals and just stuck to half steps.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-12-27","id":11,"permalink":"/posts/half-steps/","summary":"Originally posted on Substack.\nTry it out here if you like pressing buttons as much as I do! GitHub if you like reading code.\nDuring the holidays, I wanted to get better at answering questions like ‚Äúwhat is 7 half steps up from A?1‚Äù I often found myself in the situation of having these problems as a lot of guitar chord sheets are written something like ‚ÄúA capo 7‚Äù which means you put the big barre thing on your guitar and play an A-shape chord. When using a capo, the actual underlying chord is \u0026lsquo;A + 7 half steps\u0026rsquo;. This means if you\u0026rsquo;re collaborating with another instrument or with someone not using a capo, you need to communicate the actual chord you\u0026rsquo;re playing. This requires some mental math, which I found slightly embarrassing as I didn\u0026rsquo;t always immediately know what chord I was playing.\n","tags":["tech","music"],"title":"I made a web app to get better at adding half-steps to notes"},{"content":"Originally posted on Substack\nYou know the first verse of the Bible, right?\nIn the beginning, God created the heavens and the earth.\nGen 1:1 NET\nThe word for God here is Elohim. There are some interesting tidbits about this:\nThe noun is in its plural form. Singular would be Eloah. While this seems really controversial, in most of the usages, it‚Äôs paired with a singular verb. AKA ‚Äúcreated‚Äù up there is masculine singular. So it‚Äôs often interpreted as a majestic plural.\nAlso, the word is kind of impersonal. We often use the word to describe other gods in the bible.\nYou shall have no other gods before me\nExo 20:3 ESV\nIn that verse, the word is also elohim, and is often translated as lower capitals to indicate it‚Äôs not talking about the Jewish God.\nHowever, something fascinating is that Genesis isn‚Äôt consistent with what term it uses for God. Not just in the whole book, but literally by chapter 2. In chapter 2, the writer(s) start using Yahweh Elohim instead of Elohim. My translation notes this difference by writing it as ‚ÄúLORD God‚Äù instead of just ‚ÄúGod‚Äù or ‚ÄúLord‚Äù:\n‚Ä¶when the LORD God made the earth and heavens.\nGen 2:4 NET\nYou can actually pretty easily spot the difference if you check out the Hebrew. Yahweh Elohim looks like this: ◊ô◊î◊ï◊î ◊ê◊ú◊î◊ô◊ù, whereas Elohim looks like this: ◊ê◊ú◊î◊ô◊ù. A reminder that Hebrew is right-to-left üôÇ. So the difference between these two is just the presence of the tetragrammaton / the personal name of God (Yahweh).\nIsn‚Äôt that odd? That God changes names within two chapters? Or that it kind of zooms in on specificity in Genesis 2? Another thing that‚Äôs odd is that God hasn‚Äôt actually revealed his name to the readers / Jewish people yet in the story. Rather, the Jewish people don‚Äôt even exist, as it‚Äôs the creation narrative. God reveals his name, Yahweh, in Exodus 3:15, as well as a brief etymology in 3:14.\nMy thoughts are that this is pretty strong evidence that Genesis 2 is a different creation account + has a different author, possibly writing later in time, as this seems to be an anachronism. Another way to think of this is that Genesis 1 and Genesis 2 serve different purposes.\nStill forming opinions and thoughts, but this is a pretty interesting find for me.\n","date":"2023-10-10","id":12,"permalink":"/posts/the-first-use-of-yhwh-in-the-bible/","summary":"Originally posted on Substack\nYou know the first verse of the Bible, right?\nIn the beginning, God created the heavens and the earth.\nGen 1:1 NET\nThe word for God here is Elohim. There are some interesting tidbits about this:\nThe noun is in its plural form. Singular would be Eloah. While this seems really controversial, in most of the usages, it‚Äôs paired with a singular verb. AKA ‚Äúcreated‚Äù up there is masculine singular. So it‚Äôs often interpreted as a majestic plural.\n","tags":["christianity"],"title":"The first use of YHWH in the Bible is pretty odd"},{"content":"Originally posted on Substack\nI‚Äôve often encountered Christians that believe the world was created in 7 24-hour days, because ‚Äúthat‚Äôs what the Bible says‚Äù in Genesis 1 and they won‚Äôt believe otherwise.\nThere are a ton of arguments against this ‚Äúfact,‚Äù but I think the most compelling one is the linguistic ambiguity for the word ‚Äúday‚Äù (yom) used in the creation account. First, let‚Äôs take a look at an English translation for one of the days of creation:\n\u0026ldquo;God called the light Day (yom), and the darkness he called Night. And there was evening and there was morning, the first day (yom).\u0026rdquo;\nESV Genesis 1:5\nThe Ancient Hebrew word used here ‚Äúyom‚Äù ◊ô◊ï÷π◊ù, can mean the following things based on its entry on Wikipedia:\nPoint of time (a specific day) time period of a whole or half a day: Period of light (as contrasted with the period of darkness), Sunrise to sunset Sunset to next sunset General term for time ( as in \u0026lsquo;days of our lives\u0026rsquo;) A year \u0026ldquo;lived a lot of days\u0026rdquo; Time period of unspecified length. \u0026ldquo;days and days\u0026rdquo; Now, if you were brought up in the education system, you probably know that Wikipedia isn‚Äôt a valid academic source üòõ. However, it does seem to indicate that something interesting is going on here as the word can mean drastically different time extents based on the context. One way to learn a bit more is to compare other usages of the word yom in Genesis (the word is used throughout the Hebrew Bible ‚Äî I thought it‚Äôd be best to focus just on Genesis as we can assume it was edited as one writing piece).\nNote that yamim is the plural of yom for the following examples, as there aren‚Äôt actually a lot of usages of the singular form beyond the creation account.\n‚ÄúIn the course of time (yamim) Cain brought to the LORD an offering of the fruit of the ground‚Äù\nESV Genesis 4:3\nThis is the loosest translation of yom I could find in Genesis. The way the ESV has rendered it looks pretty similar to the English phrase ‚ÄúIn these days‚Ä¶‚Äù which is also very non-specific when it comes to extent.\n‚ÄúNow Abraham and Sarah were old, advanced in years (yamim). The way of women had ceased to be with Sarah‚Äù\nESV Genesis 18:11\nYears?! What?! I guess you could say ‚Äúadvanced in days.‚Äù\nAnd God said, ‚ÄúLet there be lights in the expanse of the heavens to separate the day (yom) from the night. And let them be for signs and for seasons, and for days (yamim) and years\nESV Genesis 1:14\nSimilar to Genesis 1:5 where the word is used both to describe daytime as well as specific time extents. This is most likely a literal day, as the words used for ‚Äúseasons‚Äù and ‚Äúyears‚Äù are more specific as well.\nThese are the generations¬†of the heavens and the earth when they were created,¬†in the day (yom) that the Lord God made the earth and the heavens.\nESV Genesis 2:4\nThis one is a bit trickier for me. The verse is right before the creation of humanity in Genesis 2 (which happens during the events of Genesis 1). In MSG and NLT, the word ‚Äúday‚Äù doesn‚Äôt even show up, nor does any extent of time. As this prefaces the writer(s) zooming into humanity‚Äôs creation, it could be referring to the specific day that happens on, but my pretty uneducated guess is that it‚Äôs an extent of time that refers to the whole creation timeline, kind of serving as a capstone of the creation account.\nUltimately, the word is ambiguous. Readers often come into Genesis with their preconceived notions of what it should say and how the world was created and then attempt to make an interpretation of this thousands-of-years-old text. Instead of fully pushing this argument into a dichotomy, I want to make the following point: it‚Äôs ok to not know what‚Äôs going on in the creation account for sure. It‚Äôs also really hard to get into the writers‚Äô headspace and really think: what were they trying to say through Genesis 1? What did they care about? Maybe nailing down that days were slightly less than 24 hours or the commonality of carbon throughout the universe weren‚Äôt exactly top thoughts?\nI think it‚Äôs short-sighted to make strong claims about what precisely the Hebrew Bible says without even attempting to investigate the original language, so go for it! I used a free tool called Logos to look up the Hebrew inline \u0026amp; compare different translations. Don‚Äôt blindly believe what you hear: check it! Also this post isn‚Äôt intended to completely discredit the creation of the world in 7 literal days. In a worldview where God exists and is omnipotent, anything can be accomplished, even if it‚Äôs manufacturing evidence that the world was created over a much longer span of time. But yes, your call on what side of the argument you‚Äôre on. Cheers!\n","date":"2023-06-14","id":13,"permalink":"/posts/yom-examining-creations-timeframe-with-linguistics/","summary":"Originally posted on Substack\nI‚Äôve often encountered Christians that believe the world was created in 7 24-hour days, because ‚Äúthat‚Äôs what the Bible says‚Äù in Genesis 1 and they won‚Äôt believe otherwise.\nThere are a ton of arguments against this ‚Äúfact,‚Äù but I think the most compelling one is the linguistic ambiguity for the word ‚Äúday‚Äù (yom) used in the creation account. First, let‚Äôs take a look at an English translation for one of the days of creation:\n","tags":["Christianity"],"title":"Yom: Examining Creations Timeframe With Linguistics"},{"content":"Originally posted on Substack\nedit: this blogpost was initially wrong when I published it. Thanks to some comments I got, I learned I didn‚Äôt fully understand TrueTime or Spanner ‚Äî I‚Äôve spent some time learning and understanding the core concept again, and have updated this artifact. This is an externalized resource for me that I hope can be helpful for others.\nWhen I was reading the famous paper on Spanner, Google‚Äôs globally distributed linearizable database, I really struggled with the concept of TrueTime, which is a core component of why they were able to get their guarantees. After trying to wrap my head around it, I created the following artifact (IMO, TrueTime deserves a mini-ish paper or post on its own):\nSo first, let\u0026rsquo;s assume that we have a way to globally agree in a distributed fashion on a single value (this is Paxos, which I won\u0026rsquo;t be going into here). In this case, we want that value that all nodes to agree on to be the correct ordering of transactions. However, even with such a powerful primitive, if we were to just use normal timestamps, we‚Äôll still have issues actually assigning an order to transactions.\nClocks are always inaccurate. Not just a set amount from the current time ‚Äî they unfortunately also drift. And in different amounts from each other. So in distributed systems, clock synchronization is a hard problem, and generating timestamps that are ordered globally is nontrivial.\nImagine you wanted to globally order transactions by what time they committed. If a clock was off even between two nodes, we already are SOL if we use the local time as the ordering constraint:\nSo given nodes A and B with TXNs, and given \\(T_A, T_B| T_A \u003c T_B\\), where \\(T_A\\) and \\(T_B\\) are transactions on nodes A and B, and the \u0026lt; sign indicates that ‚Äútransaction A precedes transaction B,‚Äù if we were to attempt to globally order the TXNs based on reported timestamp, we‚Äôd conclude that \\(T_B \u003c T_A\\).\nThis breaks causality. Imagine \\(T_B\\) depended on \\(T_A\\); e.g. \\(T_B\\) was a message reply to \\(T_A\\). So even if we were to have global agreement on the ordering of transactions, if we use the local timestamps that node A and B generate, the ordering will be incorrect.\nClocks aren‚Äôt just slightly inaccurate. They‚Äôre like 100s of milliseconds inaccurate, which can lead to large windows where causality will be broken.\nSo imagine we were able to somehow guarantee that all the clocks are \\(\\pm\\) 3.5ms of the actual time. So all clocks in the system are 7ms of each other (we‚Äôll call this e. Google actually has this guarantee with the use of GPS + atomic clocks).\nGiven this, we can actually generate a total ordering even with clocks that are off. First, instead of storing just one number as the timestamp for a transaction, every transaction has a [start, end] bound. end - start = e, and the actual timestamp \u0026amp; the local timestamp are both within the range. Let‚Äôs revisit our previous example, but now with time intervals:\nSo as before, if we were to rely on the ‚Äúreported time,‚Äù we would come to the wrong conclusion that \\(T_B\\) happened before \\(T_A\\). Here‚Äôs a simple fix though now that we have intervals: in the case where we have a conflicting transaction with overlapping intervals, make it so that the one with the later start time waits until it‚Äôs no longer overlapping. Concretely, make \\(T_B\\) wait until it‚Äôs interval has at least a start of 2. If we were to do this, then there‚Äôs no way \\(T_A\\) and \\(T_B\\) can have incorrect ordering.\nThe key takeaway is that since we have the intervals, we have a bound on how long to wait until there‚Äôs no longer a conflict. Before, we couldn‚Äôt be sure with just the local timestamps that there was a problem, as we didn‚Äôt have a bound on the timestamps‚Äô uncertainty.\nBrief thoughts on Spanner# I‚Äôve handwaved some of the finer details on how TrueTime is used in Spanner to keep the scope of this blogpost small. However, technically the scheme I described should be correct to generate a total ordering.\nWhile Google went about creating a globally distributed serializable database like this, there haven‚Äôt been many follow-ups that build off of this from my knowledge. This could be for a lot of reasons that I‚Äôm definitely not an authority on, but some ideas:\nDevelopers are ok with dealing with eventual consistency Google‚Äôs implementation of Spanner is too expensive ‚Ä¶or the people who want the guarantees are just using the GCP version The players who deal with scaling problems like this already have their own solutions, public or not. Regardless, it was fun to learn about this and hopefully this was helpful üôÇ\nAppendix# Why are the reported times not at the center of the TrueTime intervals?\nI‚Äôm not entirely sure about this, but (1) the API doesn‚Äôt actually specify where the reported time is ‚Äî just that it‚Äôs an interval. I‚Äôm guessing it‚Äôs possible for the local time to drift within the interval and it depends on factors like network synchronization and the tendency of the local clock to drift.\n","date":"2023-06-04","id":14,"permalink":"/posts/spanner/","summary":"Originally posted on Substack\nedit: this blogpost was initially wrong when I published it. Thanks to some comments I got, I learned I didn‚Äôt fully understand TrueTime or Spanner ‚Äî I‚Äôve spent some time learning and understanding the core concept again, and have updated this artifact. This is an externalized resource for me that I hope can be helpful for others.\nWhen I was reading the famous paper on Spanner, Google‚Äôs globally distributed linearizable database, I really struggled with the concept of TrueTime, which is a core component of why they were able to get their guarantees. After trying to wrap my head around it, I created the following artifact (IMO, TrueTime deserves a mini-ish paper or post on its own):\n","tags":["tech"],"title":"My Notes on Google's TrueTime"},{"content":"Originally posted on Medium.\nthey really do. I have most of them turned off on my phone.\nfirst, idk who to blame about these, but there is this class of notifications that are like\n‚Äúfeeling hungry? order UberEats now!!‚Äù\nsomeone gave someone this lever to pull to increase engagement. the first someone upsets me, and i sometimes think about the other someone and also get angry.\ni turn all of these off, when I can actually turn them off. in the case where an app doesn‚Äôt let me disable them, I turn off all notifications for that app. they‚Äôve lost my trust.\nonce you start turning these off, you realize that most notifications are actually just avenues for companies trying to boost your engagement with their apps. like those reddit notifications you get about random people posting? totally for engagement. do you actually need to hear from them? no! turn them off. give me my autonomy: i‚Äôd rather pull than be pushed.\nalso i wish I could cancel badges. i turned them all off, because WHY. there‚Äôs something in my brain that makes me want to clear them. maybe i have a problem. idk. I can‚Äôt disable the settings app badge though so that‚Äôs bothering me right now but don‚Äôt worry we have more to talk about\nmessaging notifications# ok, so once we‚Äôve cut these out, we now have what I call ‚Äúmessaging notifications.‚Äù these are actually things I care about. like my friends reaching out to me!\nhowever, i turn these off sometimes too via Do Not Disturb. often people reaching out to me can really take me away from my present or ruin my focus. imagine you‚Äôre having dinner with someone but you keep reading messages from other people or messaging them ‚Äî isn‚Äôt that really sad? you literally have someone of infinite depth right in front of you! talk to them!\nbut also, there are some notifications that are really mentally heavy, and could completely ruin your day. i‚Äôve definitely gotten some of these messages. if possible, i‚Äôd like to handle these things when i‚Äôm not working or having a good time with friends, since it‚Äôll just change my reality. you know, there used to be times when people weren‚Äôt reachable 24/7. maybe there was some implicit wisdom to that (can‚Äôt be explicit because people back then probably had no idea we‚Äôd be where we are now).\nwork# ah yes. work. work notifications. these are a mess. i actually always have them disabled, but when I need to be around to respond to things (like support oncall), i dedicate 1/3 monitors to a fullscreen slack. idk if that‚Äôs a good idea. it has its pros and cons. try it out (well if you have a screen to spare).\nsome people really do be slacking all day. like, you know, using the slack app. not me; I find that most of my work is creative or like churning something out. don‚Äôt need to talk to someone to do that!\nconc# not sure if this helps anyone out there, but i‚Äôve just been so DONE with notifications as a concept. i hope you can claim some of your autonomy back. ‚ù§\nstephen\nfurther reading# https://www.reddit.com/r/ProgrammerHumor/comments/60wx3z/this_is_why_you_shouldnt_interrupt_a_programmer/ trigger-action planning ","date":"2023-06-02","id":15,"permalink":"/posts/notifs-suck/","summary":"Originally posted on Medium.\nthey really do. I have most of them turned off on my phone.\nfirst, idk who to blame about these, but there is this class of notifications that are like\n‚Äúfeeling hungry? order UberEats now!!‚Äù\nsomeone gave someone this lever to pull to increase engagement. the first someone upsets me, and i sometimes think about the other someone and also get angry.\ni turn all of these off, when I can actually turn them off. in the case where an app doesn‚Äôt let me disable them, I turn off all notifications for that app. they‚Äôve lost my trust.\n","tags":["tech"],"title":"Notifications Suck"},{"content":"Originally posted on Medium.\nI use git a ton in work and my personal life, and have come up with a couple of aliases that have made using it so much more pleasant and fast. First, I‚Äôve renamed git to g. You have no idea how much typing that‚Äôs saved me (I also don‚Äôt know).\nalias g=\u0026#34;git\u0026#34; Aliases# git allows you to alias commands. In the spirit of renaming commands to one character, here are my favorite aliases:\n[alias] d = diff --color s = status p = push c = checkout a = add cm = commit -m pl = pull cl = clone r = rebase b = branch These are all in my ~/.gitconfig file. So when you navigate into a folder for the first time and want to type git status, that translates to g s. Look how short that is! Or writing a commit would be g cm 'commit'. Wow!!\nYou can also set aliases from the git CLI which will modify the .gitconfig:\ngit config --global alias.c \u0026#39;checkout\u0026#39; Some other functions# add-commit-push: I often push a ton of commits to my branches, as my organization (and projects) usually squash PRs. So I made a function to do this in one command:\nfunction acp { g a -u \u0026amp;\u0026amp; g cm $1 \u0026amp;\u0026amp; g p } This function:\nadds all tracked files (so doesn‚Äôt add new files) commits with the message that you pass in pushes So the usage goes something like acp 'commit'.\ngit-merge-master: I also often need to merge in the commits from master, usually to unbreak CI üòû. I don‚Äôt use rebases often as when you create PRs, rebases can mess up the comments once you force push. So here‚Äôs my command for gmm:\nalias gmm=\u0026#34;g c master \u0026amp;\u0026amp; g pl \u0026amp;\u0026amp; g c - \u0026amp;\u0026amp; g merge master --commit --no-edit\u0026#34; ZSH branch name# Now that MacOS X‚Äôs default terminal is zsh by default, more people are using zsh over bash. If you‚Äôre like me, you probably picked one of the many pretty themes (I picked agnoster) that also had the nice functionality of telling you a) if you‚Äôre in a git repository and b) what branch you‚Äôre on. This is super great as you don‚Äôt need to do a git status every time you enter a git repository.\nHowever. The way most of these themes implement this feature is by doing a git status every single time the prompt comes up. Which means most likely every time you press enter. I specifically had a repo that took a really long time to run git status; on the order of \u0026gt; 2 seconds. That means that every time I pressed enter, I had to wait for 2 seconds for the prompt to reappear.\nAs someone who takes latency really seriously and believes that slow systems infect your mind with slothfulness, this was unacceptable. Also, intuitively it didn‚Äôt make sense that to fetch just the branch name and the fact that it‚Äôs a git repository was so slow. It was most likely because git status also checks all of the statuses of changed files, which isn‚Äôt as important information for the shell prompt.\nSo I ended up finding this StackOverflow thread on getting just the branch name into the RPROMPT. However, I don‚Äôt really like using RPROMPT as it messes up your copy-pastes in the case where you want to copy both your command and your output. So I adapted it a bit to modify my PROMPT instead and disabled ZSH themes. It looks something like this:\nGeneral tips# In bash, ‚Äî is an alias for ‚Äúthe last directory you were in.‚Äù So if you want to checkout to the last branch you were on, g c -. Or in normal git commands, git checkout -. I don‚Äôt like the normal diff tool used by git. Often for PR reviews, I‚Äôll use difftastic to compare their branch to master (you do git diff master... to diff with the last common commit, which is what GitHub spits out in its interface). To overwrite what diff tool git uses, you‚Äôll want to add this to your .gitconfig: [diff] tool = difft If you end up having a bunch of untracked files in your git repository by accident, you can nuke all of them by running git clean -fd. This is a dangerous command. Only do it if you‚Äôre ok with losing all of these files. Unsure if you can recover them via g reflog. Good job making it this far. Hopefully this helps out someone out there! I‚Äôm proud of most of my workflow optimizations, but I‚Äôm also totally looking for MORE. hmu if you have any cool tips or tricks for git, or anything really. Also I‚Äôll probably write more of these, but since a lot of them come from just using Emacs, I might have to make it Emacs-specific going forward.\n","date":"2022-12-25","id":16,"permalink":"/posts/some-quick-zsh/","summary":"Originally posted on Medium.\nI use git a ton in work and my personal life, and have come up with a couple of aliases that have made using it so much more pleasant and fast. First, I‚Äôve renamed git to g. You have no idea how much typing that‚Äôs saved me (I also don‚Äôt know).\nalias g=\u0026#34;git\u0026#34; Aliases# git allows you to alias commands. In the spirit of renaming commands to one character, here are my favorite aliases:\n","tags":["tech"],"title":"Some quick git (and zsh) workflow optimizations"},{"content":"Originally posted on Medium.\nWhy do we need AI to write blog posts? There‚Äôs been a trend of these AI tools to write things for you:\nhttps://www.notion.so/product/ai https://www.copy.ai/bloggers https://www.jasper.ai/examples/blog-posts Imagine you have something to say to people. So you come up with some representation of that thing you want to say; maybe bullet points, maybe a rant, maybe even some markdown stuck in a GitHub repository. Why can‚Äôt you just publish that?\nit‚Äôs probably more concise. AIs seem to expand things in an unpredictable fashion it‚Äôs your voice! speak loud! don‚Äôt hide behind some jank code. Some ‚Äúbenefits‚Äù:# SEO\nJasper advertises writing posts that‚Äôll have better SEO Really short posts will be harder to find, and there‚Äôs been a trend of making medium-sized articles even when the content amount is low for ranking. Just look at recipes on Google üòï I think SEO has messed up content in the last decade. Misc\nThere‚Äôs a reason people don‚Äôt just publish their diaries or journals online all the time. Writing publicly requires you to adapt your mental models so that other people besides yourself can understand. Maybe AI can do this? Maybe not? ü§∑ CopyAI: You can ‚Äúfocus on the things you love‚Äù and free up your time from writing posts. OK, if you don‚Äôt love writing, why are you doing it? Maybe the act of creating an artifact about the thing you love can become a thing you love? Either way, I wrote this by hand in Notion. I also drew the above graphic on my iPad ‚Äî here‚Äôs what OpenAI spit out for memes:\nPrompt: a stick figure diagram of a person talking to a robot, which is trying to talk to a group of people. however, the robot can‚Äôt talk, and instead the person has to shout around the robot I probably won‚Äôt be entertaining AI writing my writings anytime soon. This is the exact type of post I like: has a strong opinion, concise, and potential for discourse. LMK if there are reasons this could be a good thing. Keep it real homies\n","date":"2022-12-03","id":17,"permalink":"/posts/im-against-ai-blog/","summary":"Originally posted on Medium.\nWhy do we need AI to write blog posts? There‚Äôs been a trend of these AI tools to write things for you:\nhttps://www.notion.so/product/ai https://www.copy.ai/bloggers https://www.jasper.ai/examples/blog-posts Imagine you have something to say to people. So you come up with some representation of that thing you want to say; maybe bullet points, maybe a rant, maybe even some markdown stuck in a GitHub repository. Why can‚Äôt you just publish that?\n","tags":["tech"],"title":"I‚Äôm against AIs writing blog posts"},{"content":"Originally posted on Medium.\nPlease. It‚Äôs an insult to my brain. Like, you put the button in one place, and then you‚Äôre like ‚Äúnah, let‚Äôs move it somewhere else.‚Äù Here are some examples that have annoyed me the most lately:\nLyft Bike Scan Button# This one sucks as I‚Äôm often opening the Lyft app just to ride bikes. So I immediately hit the bike button and I‚Äôm trying to hit the ‚ÄúScan‚Äù button as quickly as possible. But no! Depending on how fast my internet is at the current moment, that banner will appear and push the Scan button up, which means I end up hitting the banner instead üòü; this is often a really frustrating start to my daily commute.\nNotion search results# ignore the page titles for your own sanity\nI use Notion as a power user at this point. When I‚Äôm trying to navigate to a page, I‚Äôll press CMD+K to open the doc finder, and then type in some prefix of what I‚Äôm looking for. To pick a result, I‚Äôll be using CTRL+P or N to go up and down, and often press enter in under a second. What‚Äôs crazy about this is it first returns one set of results, and then a pretty different set of results. IIRC rarely even the first result will change üòï.\nWhy it happens# Some ideas:\nLoading something and inserting it in a way that moves around other elements More complicated queries that would reorder the results. e.g. it appears the Notion search first returns title searches, and then actually searches the contents of documents which ends up in result reordering. What I call ‚ÄúUX fragmentation‚Äù. When personas of users differ so much or there are so many experiments running, that engineers and designers aren‚Äôt fully aware of what end-users are seeing. You‚Äôve probably seen this with features being A/B tested. Sometimes, things are loaded in one order or another order depending on a plethora of variables. And also the timing of network responses. Do better# When you make a change to the screen, why not just commit to where it should be? Do the users and the metrics get benefit from ‚Äúpseudo-responsiveness‚Äù? If the answer is yes just to the latter, I think it‚Äôd be fair to deem this a capitalistic-UX-anti-pattern. Get it out.\nIf anyone‚Äôs put thought into this or is annoyed by this, please lmk or send me resources and further readings so I can get more annoyed. Thanks:)\n","date":"2022-11-25","id":18,"permalink":"/posts/frontend-devs-stop-moving/","summary":"Originally posted on Medium.\nPlease. It‚Äôs an insult to my brain. Like, you put the button in one place, and then you‚Äôre like ‚Äúnah, let‚Äôs move it somewhere else.‚Äù Here are some examples that have annoyed me the most lately:\nLyft Bike Scan Button# This one sucks as I‚Äôm often opening the Lyft app just to ride bikes. So I immediately hit the bike button and I‚Äôm trying to hit the ‚ÄúScan‚Äù button as quickly as possible. But no! Depending on how fast my internet is at the current moment, that banner will appear and push the Scan button up, which means I end up hitting the banner instead üòü; this is often a really frustrating start to my daily commute.\n","tags":["tech"],"title":"Frontend developers: stop moving things that I‚Äôm about to click on"},{"content":"Originally posted on LinkedIn as a meme.\ni‚Äôve been thinking about the big rocks every day\nfor those who don‚Äôt know: https://lnkd.in/gZGfgBE9\njust the other day, i was at whole foods. and i tried to fit the items into my cute tote bag haphazardly. they didn‚Äôt fit!!\nbut then, i put the straus whole fat milk first. and then the yogurt. and then i put the cheese, and the cute lil snax. i fit everything! the bag was kinda heavy though.\nthink about your big rocksü™®ü™®ü™®ü™®\n","date":"2022-11-23","id":19,"permalink":"/posts/big-rocks/","summary":"Originally posted on LinkedIn as a meme.\ni‚Äôve been thinking about the big rocks every day\nfor those who don‚Äôt know: https://lnkd.in/gZGfgBE9\njust the other day, i was at whole foods. and i tried to fit the items into my cute tote bag haphazardly. they didn‚Äôt fit!!\nbut then, i put the straus whole fat milk first. and then the yogurt. and then i put the cheese, and the cute lil snax. i fit everything! the bag was kinda heavy though.\n","tags":["tech"],"title":"Big Rocks"},{"content":"Originally posted on LinkedIn as a meme.\nmy friends are all attachment styles this and attachment styles that when it comes to dating. however, has anyone had the brilliant idea of applying attachment styles to working at a tech company? I didn‚Äôt think so! now you might be thinking, ‚Äúhey Stephen isn‚Äôt this a bad idea?‚Äù and yes, it is. but just like we should all hope to be secure partners in our relationships, we should also possibly strive to be secure capitalistic partners at work.\nfirst, what are attachment styles? from my very topical reading and a lot of projection, here‚Äôs a short summary as well as some relevant spotify songs. there are three styles: anxious, avoidant, and secure. anxious people (‚Äùinside out‚Äù, ‚Äúused to you‚Äù) are often overinvested to the point of destruction in their relationships, constantly misperceiving slight signals as catastrophes. avoidant people (‚ÄùLet‚Äôs Fall In Love‚Ä¶‚Äù) create distance from their partners when their intimacy lines start getting crossed. secure people are great. go read the book ‚ÄúAttached‚Äù if you‚Äôd like more information or potential trauma\ni think the following section is best suited as a list. NOTE that me listing them here isn‚Äôt me condemning these behaviors as I totally do them all the time. but maybe there‚Äôs something to think about ü§î. here are some avoidant traits at work:\nsetting your slack status to offline or away all the time large ‚ÄúDO NOT BOOK‚Äù blocks on your calendar restricting personal interaction / not attending social events at your company copying and pasting in your responses from another app so that people can‚Äôt see you typing not having a slack profile picture with your face in it refusing to read your email turning off notifications and only triaging if things are escalated skipping all hands reading a message and pretending not to read it ‚Ä¶or marking it as unread so you can deal with it later, but then accidentally reading it and then never triaging writing in lowercase in a lot of these cases, these are defense mechanisms employed to make good use of your time. though it‚Äôs still useful to reflect on them instead of just doing them automatically.\nand anxious:\nbeing in multiple meetings at the same time so you don‚Äôt miss anything pressing enter too many times and sending tons of messages. and getting anxious when people don‚Äôt reply instantly stream of consciousness style typing replying instantly ‚Äúwhy is your status away‚Äù double posting in the #social channel ‚Äúwhy is no one reacting to my message‚Äù creating PRs for attention saying yes to everything so that your coworkers will like you long pairing sessions to get social contact ‚Ä¶at this point i‚Äôm just recounting my own habits secure: honestly i have no idea that would be nice.\ni pride myself at being anxious-avoidant at work, the worst of the lot. have fun misclassifying yourself and your coworkers!\n","date":"2022-09-17","id":20,"permalink":"/posts/attachment-styles-at-work/","summary":"Originally posted on LinkedIn as a meme.\nmy friends are all attachment styles this and attachment styles that when it comes to dating. however, has anyone had the brilliant idea of applying attachment styles to working at a tech company? I didn‚Äôt think so! now you might be thinking, ‚Äúhey Stephen isn‚Äôt this a bad idea?‚Äù and yes, it is. but just like we should all hope to be secure partners in our relationships, we should also possibly strive to be secure capitalistic partners at work.\n","tags":["tech","dating"],"title":"Attachment Styles at Work"},{"content":"Originally posted on the Plaid Engineering Blog while I was part of Plaid\u0026rsquo;s Developer Experience Team.\nThe developer experience team focuses on building tools and features that make it as easy as possible for developers to explore our APIs and integrate with Plaid. This year, our team adopted an OpenAPI schema (OAS) as a specification for our API. We launched this schema in beta earlier this year.\nOur team is responsible for maintaining three sources of truth for our API that allow developers to build and test their integrations:\nthe docs our language SDKs, which we call the CLibs (Client Libraries) the actual API :) Over time, we realized keeping all three of these developer-facing surface areas updated and synchronized can be a challenge as our API evolved. Ideally, we wanted one source of truth for our API in order to enforce a consistent experience for external developers, which is why we decided to use an OpenAPI schema as a point of reference to generate the docs, the client libraries, and part of our API.\nWe learned some valuable lessons along the way that we wanted to document and share so that other teams taking on similar projects could benefit. In this article, I\u0026rsquo;m going to walk through how we decided to use the OpenAPI schema at a company with an existing API that we are continuously iterating on, challenges we encountered, and how we overcame them.\nPhilosophy# When we first started generating our SDKs, the bulk of the issues we ran into initially were around making sure our OpenAPI schema was an accurate representation of our API. However, after we resolved most of these issues, we started running into another class of problems \u0026ndash; issues with the generated output of the libraries. For dealing with these issues, there were a couple of things we could modify to improve the generated output:\nThe actual Plaid API implementation OpenAPI schema: sometimes we could use different methods of representing the API within OpenAPI. Also, some features of the OpenAPI version we used weren\u0026rsquo;t fully implemented by all the code generators \u0026ndash; we would abstain from using these features. The actual generator implementation: The project that we ended up using for code generation is OpenAPI Tool\u0026rsquo;s generator. Each code generator is implemented in Java. We could fork the generator and modify this implementation to fit our needs. Templates: The code generators use mustache templates for each language. While we couldn\u0026rsquo;t completely change the output code by modifying templates, we could easily add helper methods or slightly change patterns. Generator parameters: the generator we used had a long list of parameters you can configure, such as packageName, version, and others. Some of these parameters can drastically affect code output. Pre-processing or post-processing the schema or code. For example, we could use scripts to insert in new files like a README.md or modify import paths with a find-and-replace. We wanted to see how feasible modifying the OpenAPI Tools generator was to fit our purposes. We embarked on a short project to try to match our existing plaid-python library through generation by making sweeping adjustments to the Java implementation. We found that our changes were all pretty brittle as matching the questionable patterns in the old plaid-python library was difficult and arbitrary. For example, some endpoints were ordered by product, so /transactions/get would be client.Transactions.get(...). This requirement was enforced inconsistently at times; for example, /accounts/balance/get\u0026rsquo;s method signature was client.Balance.get. This made it difficult to generate code that fit the existing library perfectly. Matching parameter ordering was also near to impossible without a ton of one-off generator edits.\nFinally, we had a latent desire to not commit Java code at Plaid as we mostly don\u0026rsquo;t use Java internally. This resulted in us ruling out any generator implementation changes. Another added bonus of not modifying the generator is that other developers outside of Plaid can generate a working library without using our forked generator!\nTemplate changes were frustrating in general, as we had to have some idea about the generator implementation to modify them. Luckily, our small project with the generator implementation helped us out when making template changes.\nThis exploration helped us stack rank which changes to try first. We came up with something like this:\ngenerator parameters \u0026gt; OAS \u0026gt; templates \u0026gt; any type of processing on the OAS or output code \u0026gt; the Plaid API Header secrets / POST secrets# Usually APIs have some form of authentication. Plaid\u0026rsquo;s endpoints are a little unique in the following way:\nEvery endpoint is an HTTP POST with a JSON attached. For authenticated endpoints, the JSON requestBody has client_id and secret attached as parameters. While this is a reasonable way to authenticate endpoints, it isn\u0026rsquo;t a pattern that OpenAPI supports out-of-the-box. OpenAPI supports BasicAuth and header keys, as well as some other forms of authentication. In old versions of the OpenAPI schema, we ended up having client_id and secret as required parameters in every requestBody. While this was correct and worked, when we generated the library, it made it so calling any endpoint required you to pass in the authentication again.\nold not generated library\nclient.TransactionsGet(params...) default output of generator\nclient.TransactionsGet(client_id, secret, params...) This would have made using our library pretty frustrating as developers would have to wire their Plaid client_id and secret throughout their application and pass it into every endpoint call.\nAs engineers, we disliked the unnecessary complexity, so we considered two options:\nTry to modify the generator to attach authentication on the right endpoints Modify our API and OAS to match an OpenAPI authentication schema Since we were opposed to modifying the generator, we decided to adopt an OpenAPI authentication schema. We discovered that some routes in the past supported header-based authentication where the client_id and secret were sent in the headers under the keys PLAID-CLIENT-ID and PLAID-SECRET. We decided to adopt this standard. However, we didn\u0026rsquo;t want to cause a breaking change to our API by fully migrating to this new pattern. It was important to us that our old libraries were still compatible with the API! So we devised the following solution for every client-facing route: accept authentication either in the headers OR in the request body.\nWe modified every route to have this new authentication and also marked client_id and secret as optional in the requestBody. This allowed us to have a similar pattern to the old client libraries where authentication is passed in automatically, as OpenAPI supports this type of authentication. The library ended up attaching the authentication in the headers for the correct endpoints. Yay!\nAdditive changes don\u0026rsquo;t break JSON (additionalProperties)\nAt Plaid, we\u0026rsquo;ve always treated additive changes to endpoints as non-breaking. This allows us to rapidly ship new functionality and features without forcing developers through API migrations.\nImagine an endpoint that officially returned named parameters (x, y), but one day, the endpoint starts returning (x, y, z): this is consistent with JSON Schema and is ok. It is also valid according to the OpenAPI specification, which states \u0026ldquo;additionalProperties defaults to true\u0026rdquo; for objects, describing this behavior.\nIn our old client libraries, we generally handled additional parameters returning from the API gracefully and just dropped them. However, most of the generators either assumed additionalProperties was false by default and/or did not work correctly with it set to true:\nThe Python generator assumed additionalProperties was false. Upon receiving a response that had extra parameters, the library crashed on deserialization. This is when we decided to add additionalProperties: true to every response model, as we\u0026rsquo;re ok with over-specifying values in our OpenAPI schema even if they\u0026rsquo;re default. The other libraries either dropped values if additionalProperties wasn\u0026rsquo;t set to true, or they\u0026rsquo;d stick it in a map. The default output of the Java generator was a mess. Adding additionalProperties at all to any response model caused an inheritance bug where the model extended HashMap but didn\u0026rsquo;t properly implement the interface. The output code didn\u0026rsquo;t compile, and we couldn\u0026rsquo;t really figure out how to fix it through templating. The behavior when not having additionalProperties was just to drop additional values; we were ok with this. We added a pre-processing step to the OpenAPI file to remove all instances of additionalProperties before handing it to the Java generator. This particular issue was a headache. If you run into this issue, make sure to check all your languages\u0026rsquo; outputs carefully. We debugged this by picking an endpoint that was easy to call with minimal setup (one example for the Plaid API is /categories/get). We would set additionalProperties to true, and then remove a known parameter from the response model of the endpoint. We then fired up the generated code and saw what happened when the library received an unexpected response parameter \u0026ndash; if it didn\u0026rsquo;t crash, we were in the clear.\nRequest and response models inconsistently implemented# In OpenAPI, you can either define your request and response\u0026rsquo;s schema inline or use a $ref to point to a named model. In the initial revision of the OpenAPI schema, all of our endpoint schemas were defined inline something like this:\nendpoint: responses: object: ... requestBody: object: ... We hoped that when generating Python, it would just pick an order for the parameters and output something like:\nclient.Endpoint(requiredParams..., optionals...) Nope. Instead, the generator ended up creating anonymous models called something like inline_model_xx. The endpoint would look like this:\nclient.Endpoint(inline_model_xx(requiredParams..., optionals...)) Not ideal. Some generators flat out didn\u0026rsquo;t work correctly with anonymous objects as well (looking at you, Go). We ended up creating named request and response models for every endpoint. The endpoint TransactionsGet has an associated TransactionsGetRequest and TransactionsGetResponse. The generated code ended up using these names we provided.\nendpoint: responses: $ref: \u0026#34;endpointResponse\u0026#34; requestBody: $ref: \u0026#34;endpointRequest\u0026#34; client.Endpoint(endpointRequest(requiredParams..., optionals...)) Misc. things we had to template# There were a couple of small quality-of-life changes that we templated in. Aside from helper functions for dealing with the libraries, we also did slightly bigger changes.\nClient library initialization \u0026ndash; environments# OpenAPI allows you to define a list of servers that your API supports. Plaid supports three environments ‚Äì sandbox, development, and production ‚Äì which all have different URLs. We wanted to support these as constants and allow these constants to be easily inputted as one of the initialization arguments. We had template modifications of this form:\n{{#servers}} const {{{description}}} = \u0026#34;{{{url}}}\u0026#34; {{/servers}} // which yields code like const sandbox = \u0026#34;https://sandbox.plaid.com\u0026#34; ... While this is abusing the description field, we controlled that it was set to something reasonable :).\nVersion pinning# Some of our older client libraries (Node, Python) used to support multiple API versions, because they were thin wrappers over HTTP POST where the responses were basically dictionaries. Now that we are generating the libraries and strongly typing the responses, we only support the latest Plaid API version.\nThe way you specify what API version you\u0026rsquo;re using for Plaid is by setting the Plaid-Version header in your requests. So we added in templating to force this value to the latest API version for all libraries.\nConclusion# These were only a couple of the challenges that we ended up dealing with, and we still have many more improvements we could ship. The project shipped successfully to GA for all of our languages the week of 8/16/21. These new libraries are filled with improvements for developers, including but not limited to:\nbetter adherence to the API and docs. some language-specific features, like async support for Node and contexts for Go. consistency between languages for method names. It was really cool to slowly make these libraries something we\u0026rsquo;d be happy to use ourselves from the default generated outputs. Many of the solutions we came up with during the project focused around cutting the verbosity in using our libraries. If you want to vet the quality of your generated libraries, just try using them! Every time you run into an issue once, your developers who use your SDK will probably run into them 100s of times over.\nWe‚Äôre happy to document how we dealt with the many challenges along the way, and hope we can help fellow engineers on a similar journey.\n","date":"2021-09-15","id":21,"permalink":"/posts/plaid-adopting-openapi/","summary":"Originally posted on the Plaid Engineering Blog while I was part of Plaid\u0026rsquo;s Developer Experience Team.\nThe developer experience team focuses on building tools and features that make it as easy as possible for developers to explore our APIs and integrate with Plaid. This year, our team adopted an OpenAPI schema (OAS) as a specification for our API. We launched this schema in beta earlier this year.\nOur team is responsible for maintaining three sources of truth for our API that allow developers to build and test their integrations:\n","tags":["tech"],"title":"Adopting the OpenAPI schema to generate Plaid's SDKs"},{"content":"Originally posted on the Mobile Developers of Berkeley blog\nThis article is going to be a quick intro to the basics of writing modern JavaScript all the time, rather than being dependent on what environment is supported by a given browser.\nIntro# First, what is ES6? ECMAScript 6 is the sixth standardized version of JavaScript, which is ultimately a specification of language features. ES6 added a ton of really great features that drastically improved the ability to construct larger-scale programs with JavaScript (like constants and block scoping!). It‚Äôs important to note, as ES6 is only a specification, it‚Äôs ultimately up to the browsers to provide an implementation for these new features: often, certain browsers lag behind on implementing all these features (i.e. IE).\nSo that kind of sucks! If that was the end of the story, programmers would essentially have to use the newest version that was supported by all ‚Äúmodern‚Äù browsers. However, there‚Äôs a process called transpiling, which is like compiling, but goes from code source ‚Üí code source rather than to an executable. Luckily, there‚Äôs a really great project called Babel, which is often used to convert from newer versions of ES ‚Üí a version supported by most browsers. So from a higher level, the programmer writes code in ES6 / what they‚Äôre familiar with, the transpiler converts it to some older version of JS that runs everywhere, and then it‚Äôs added to the payload for a website / some type of node app.\nBefore we dive into how to set up the workflow, install npm (node package manager) and node as CLI dependencies (you can figure this out üòõ)\nLet‚Äôs dive into how to set up this workflow‚Ä¶First, create a new directory and initialize with npm:\nmkdir es6-everywhere cd es6-everywhere npm init # press enter a ton to initialize a default package.json mkdir src touch src/index.js Now we have our project set up, and have an entry point where we can write JS code (‚Äúsrc/index.js‚Äù). So we already have a basic setup where we can actually run any normal JS that‚Äôs supported by our version of node. If you want to try this yourself, try editing ‚Äúindex.js‚Äù to this:\nvar x = 2; console.log(x ** 2); and then run this shell command: node src/index.js.\nYou should see 4 logged to STDOUT! However, this isn‚Äôt really that exciting as this is normal JS running within NodeJS. Let‚Äôs first start by creating an npm script that executes this script using node. Begin by adding this line to package.json under ‚Äúscripts‚Äù; you should already see an entry for the example script ‚Äútest‚Äù:\n\u0026#34;scripts\u0026#34;: { ... \u0026#34;execute\u0026#34;: \u0026#34;node src/index.js\u0026#34; ES6 vs. Vanilla# Ok! We‚Äôve now kind of gotten the basic flow of executing scripts with npm. However, here‚Äôs a code snippet that may or may not work depending on your version of Node (and probably won‚Äôt work on IE 8 üòõ).\nconst square = x =\u0026gt; x * x; let value = 11; console.log(value); value = square(value); console.log(value); If I run npm execute, I actually end up getting the correct values printed out to STDOUT. However, I also have node version 12.9.0, and the whole point of this article is to write JS that‚Äôs mostly independent of what version we‚Äôre using. Also, let‚Äôs take a look at the snippet and the ‚Äúnew‚Äù features that it‚Äôs using by looking at some of the code.\nconst square = x =\u0026gt; x * x There are a couple of things going on here. First, the const keyword is new! It indicates that a given variable is deemed constant, and its value cannot be changed. However, in the case that it‚Äôs pointing to an object (like a list), that object can change, but the pointer to it cannot. In general, it‚Äôs good practice to use either const or let instead of var in ES6; this is first because of the fact that we‚Äôre specifying in the variable should be mutable or not. Also, both of these variable declarations are block-scoped rather than function-scoped (which is in-line with how some other languages handle variable scoping and a lot clearer). Here‚Äôs an example of something that works in normal JS but doesn‚Äôt work with const + let for good reason:\n{ var x = 2; } console.log(x) versus\n{ const x = 2; } console.log(x) You can try executing both of these, but basically, for the second snippet, the second example should fail. This allows for much cleaner namespacing and decreases clutter (+ makes it clear when we‚Äôre shadowing variable names in places like the block in a conditional statement).\nNow, let‚Äôs look at the right side of this line (and one of my favorite ES6 features!): x =\u0026gt; x * x. In ES6 terminology, we refer to this as an arrow-function. The two main advantages of using an arrow function are conciseness and this being lexically bound, with the possible drawback of being anonymous (no name!). The latter advantage is a bit harder to explain and is better appreciated when speaking of ES6 classes, but the first point is dope. If you‚Äôre familiar with Python, this statement is equivalent to lambda x: x * x, which is a simple square function.\nPackaging it up# Alright, let‚Äôs get back to our objective: we‚Äôre trying to convert this to older JS for compatibility reasons! We‚Äôre going to have to add some packages, but don‚Äôt worry I‚Äôll walk you through what each one does! Run this command in the ‚Äúes6-everywhere‚Äù folder:\nnpm add @babel/core @babel/preset-env babel-loader webpack webpack-cli --save-dev Let‚Äôs talk first about babel. Babel is a type of JavaScript compiler that actually compiles between JavaScript versions (also known as a transpiler, or a source-to-source compiler, as we talked about earlier). It‚Äôs pretty much exactly what we‚Äôre looking for üôÇ. Webpack is a really powerful plugin that is used primarily for bundling together tons of assets (like images, JS files, CSS files) into one website with usually one big JS file imported into one HTML file with the assets baked in. We‚Äôre going to be using webpack in order to get Babel to run on our code, as that flow will be more similar to how things would be done in production.\nWhen adding new plugins, we‚Äôre going to have to configure them. First, let‚Äôs start with Babel‚Äôs options. Create a new file in ‚Äúes6-everywhere‚Äù called ‚Äú.babelrc‚Äù, and put this in it:\n{ \u0026#34;presets\u0026#34;: [\u0026#34;@babel/preset-env\u0026#34;] } This tells babel the mode to run in, which accepts ES6 as a language input and has a default output that‚Äôs generally supported across the board. We can actually further configure the output, but we‚Äôre not going to be going into that; if you‚Äôre interested, check out the docs on @babel/preset-env.\nWebpack is a bit more complicated. Create a file called ‚Äúwebpack.config.js‚Äù and put this in it:\nconst webpack = require(\u0026#39;webpack\u0026#39;); const path = require(\u0026#39;path\u0026#39;); module.exports = { entry: \u0026#39;./src/index.js\u0026#39;, output: { filename: \u0026#39;index.js\u0026#39;, path: path.join(__dirname, \u0026#39;dist\u0026#39;), devtoolModuleFilenameTemplate : \u0026#39;[absolute-resource-path]\u0026#39;, devtoolFallbackModuleFilenameTemplate: \u0026#39;[absolute-resource-path]?[hash]\u0026#39; }, module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, use: { loader: \u0026#34;babel-loader\u0026#34; } } ], }, target: \u0026#34;node\u0026#34; } From a higher level perspective, this tells webpack a couple of things. First, our entry point (the highest level of code) is put in ‚Äúsrc/index.js‚Äù. Also, we‚Äôre going to be outputting to ‚Äúdist/index.js‚Äù. The other interesting thing is that we‚Äôre ignoring files inside of the ‚Äúnode_modules‚Äù folder; if we didn‚Äôt do this, webpack would end up compiling all of the files of the plugins that we add with babel! While we do want the code bundled in in some cases, running the transpiler on it is not what we‚Äôre trying to do. Lastly, we indicate that we should be using babel on the files that we‚Äôre considering by using the ‚Äúbabel-loader‚Äù.\nThis should be all the config we need! Let‚Äôs add another npm script to ‚Äúpackage.json‚Äù in order to actually test our config. Add this under the ‚Äúscripts‚Äù section:\n\u0026#34;yeet\u0026#34;: \u0026#34;webpack --mode development \u0026amp;\u0026amp; cat dist/index.js\u0026#34; This script runs webpack on the file that we specified in the config, and then prints out the output file ‚Äúdist/index.js‚Äù to shell. If you now run npm run yeet | tail you should see an output something like this:\nnpm run yeet | tail !*** ./src/index.js ***! \\**********************/ /*! no static exports found */ /***/ (function(module, exports) { eval(\u0026#34;var square = function square(x) {\\n return x * x;\\n};\\n\\nvar value = 11;\\nconsole.log(value);\\nvalue = square(value);\\nconsole.log(value);\\n\\n//# sourceURL=Users/ajay/programming/es6-everywhere/src/index.js\u0026#34;); /***/ }) /******/ }); We‚Äôre done! As you can see, the code has been transformed into something different (for example, our const keywords have been replaced with var keywords, and our arrow function was remade into a normal JS function). If you want to actually run the code, you can modify the yeet script to run node dist/index.js instead of printing it to the terminal, but I‚Äôll leave you to figure that out on your own.\nHave fun writing ES6 everywhere!\n","date":"2019-09-28","id":22,"permalink":"/posts/writing-es6-everywhere/","summary":"Originally posted on the Mobile Developers of Berkeley blog\nThis article is going to be a quick intro to the basics of writing modern JavaScript all the time, rather than being dependent on what environment is supported by a given browser.\nIntro# First, what is ES6? ECMAScript 6 is the sixth standardized version of JavaScript, which is ultimately a specification of language features. ES6 added a ton of really great features that drastically improved the ability to construct larger-scale programs with JavaScript (like constants and block scoping!). It‚Äôs important to note, as ES6 is only a specification, it‚Äôs ultimately up to the browsers to provide an implementation for these new features: often, certain browsers lag behind on implementing all these features (i.e. IE).\n","tags":["tech"],"title":"Writing ES6 Everywhere"},{"content":"Originally posted on Medium.\nFor my first Medium article, we‚Äôre going to go into a quick and easy way to speed up your Python code (and pass those pesky HackerRank tests where you‚Äôre just a bit short on time!), as well as some of the technical implementation details for the curious.\n__slots__ is an attribute you can add to a Python class when defining it. You define slots with the possible attributes that an instance of an object can possess. Here‚Äôs how you use __slots__:\nclass WithSlots: __slots__ = (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;) def __init__(self, x, y): self.x, self.y = x, y For instances of this class, you can use self.x and self.y in the same ways as a normal class instance. However, one key difference between this and instancing from a normal class is that you cannot add or remove attributes from this class‚Äô instances. Say the instance was called w: you couldn‚Äôt write w.z = 2 without causing an error.\nThe biggest higher-level reasons to use __slots__ are 1) faster attribute getting and setting due to data structure optimization and 2) reduced memory usage for class instances. Some reasons you wouldn‚Äôt want to use it is if your class has attributes that change during run-time (dynamic attributes) or if there‚Äôs a complicated object inheritance tree.\nTesting# Let‚Äôs first do some tests to see when __slots__ is faster, starting with mass instantiation. Using Python‚Äôs ‚Äútimeit‚Äù module and this code snippet, we get the following results:\nclass WithoutSlots: def __init__(self, x, y, z): self.x = x self.y = y self.z = z class WithSlots: __slots__ = (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;z\u0026#39;) def __init__(self, x, y, z): self.x = x self.y = y self.z = z def instance_fn(cls): def instance(): x = cls(1, 2, 3) return instance Without Slots: 0.3909880230203271 With Slots: 0.31494391383603215 (averaged over 100000 iterations) Instantiation is slightly faster with slots in this case. This makes sense, as we‚Äôre denying __dict__ creation for new instances of the given object. Dictionaries generally have more overhead than tuples or lists. Let‚Äôs try this with a class that has much more attributes associated to an instance! (This example has 26 attributes):\nWithout Slots: 1.5249411426484585 With Slots: 1.52750033326447 (averaged over 100000 iterations) In general, instantiation time is not really improved by using __slots__. Despite not having to create __dict__, there‚Äôs other overhead that needs to be done with slots that we‚Äôll go into later, which results in a similar runtime to copying over the dictionary from the actual class.\nThe real speedup comes into play when we start getting and setting values in rapid succession:\ndef get_set_fn(cls): x = cls(list(range(26))) def get_set(): x.y = x.z + 1 x.a = x.b - 1 x.d = x.q + 3 x.i = x.j - 1 x.z = x.y / 2 return get_set That‚Äôs over a 20% speed increase! I‚Äôm sure if the test was more extensive (and didn‚Äôt always access the same attributes, as well as had attributes that were longer than a single character), there could be a more substantial speedup.\nMemory Usage# First, let‚Äôs test the differences between how tuples and dictionaries grow in memory. As using __slots__ knows what attributes can exist for a given instance, it can allocate for the descriptors associated with an instance (instead of having to add a __dict__ for each new object). In Python, it‚Äôs a bit difficult to profile the exact amount of memory used by an instance of an object: sys.getsizeof only works well for primitives and built-ins. Instead, we‚Äôll be using a function called asizeof in a library called ‚ÄúPympler.‚Äù\n\u0026gt;\u0026gt;\u0026gt; asizeof((\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;)) 304 \u0026gt;\u0026gt;\u0026gt; asizeof({\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;}) 512 \u0026gt;\u0026gt;\u0026gt; asizeof(tuple(string.ascii_lowercase)) 1712 \u0026gt;\u0026gt;\u0026gt; dictionary {\u0026#39;e\u0026#39;: \u0026#39;f\u0026#39;, \u0026#39;k\u0026#39;: \u0026#39;l\u0026#39;, \u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;, \u0026#39;g\u0026#39;: \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;: \u0026#39;p\u0026#39;, \u0026#39;i\u0026#39;: \u0026#39;j\u0026#39;, \u0026#39;s\u0026#39;: \u0026#39;t\u0026#39;, \u0026#39;m\u0026#39;: \u0026#39;n\u0026#39;, \u0026#39;q\u0026#39;: \u0026#39;r\u0026#39;, \u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;y\u0026#39;: \u0026#39;z\u0026#39;, \u0026#39;w\u0026#39;: \u0026#39;x\u0026#39;, \u0026#39;u\u0026#39;: \u0026#39;v\u0026#39;} \u0026gt;\u0026gt;\u0026gt; asizeof(dictionary) 2320 We‚Äôve elided an implementation detail for the __slots__ example here: instead of having one tuple for descriptors and one for values, we‚Äôve just put them all in one list. However, we‚Äôll see the size difference isn‚Äôt that big compared to the difference between a tuple and a dict:\n\u0026gt;\u0026gt;\u0026gt; asizeof((\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;)) + asizeof((\u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;)) 352 And just for good measure, here‚Äôs what happens when we actually run asizeof on our previous example of a slotted class:\n\u0026gt;\u0026gt;\u0026gt; w1 = WithoutSlots(1, 2, 3) \u0026gt;\u0026gt;\u0026gt; asizeof(w1) 416 \u0026gt;\u0026gt;\u0026gt; w2 = WithSlots(4, 5, 6) \u0026gt;\u0026gt;\u0026gt; asizeof(w2) 160 CPython Implementation Details# So first, let‚Äôs clear some things up about what CPython is. There‚Äôs a standard implementation of the language Python and its core is written in C. It‚Äôs probably what‚Äôs installed on your machine (and what runs) when you type in python3. You can download the source here.\nI was curious to see what actually changed when defining a class with __slots__, and also just wanted an excuse to prod around CPython‚Äôs 3.7.1 release. I‚Äôll also indicate what file to check out if you‚Äôre following along at the end of each point. Here‚Äôs some key things I picked up:\nWhen __slots__ is found in the class being instantiated (it‚Äôs part of the classes default __dict__), __dict__ isn‚Äôt created for the new instance. However, the dictionary will be instantiated if you add __dict__ to __slots__, which means you can have the best of both worlds if you know what you‚Äôre doing. Files: typeobject.c type_new. Instantiating for classes with __slots__ seems like a bit more work than just creating __dict__. Essentially, you iterate through all the values defined in the class‚Äôs dictionary entry of __slots__ and have to set aside descriptors for every single entry. Check out type_new in typeobject.c for more info. Files: typeobject.c type_new. The bytecode generated for classes with slots and without is the same. This means that the differences in lookup are under how the opcode LOAD_ATTR is executed. Check out ‚Äúdis.dis,‚Äù a built-in Python bytecode disassembler. As expected, not having __slots__ ends up doing dictionary lookup: if you‚Äôre interested in the details, check out PyDict_GetItem. It ends up getting the pointer to the PyObject which holds the value by looking up in a dictionary. However, if you have __slots__, the descriptor is cached (which contains an offset to directly access the PyObjectwithout doing dictionary lookup). In PyMember_GetOne, it uses the descriptor offset to jump directly where the pointer to the object is stored in memory. This will improve cache coherency slightly, as the pointers to objects are stored in 8 byte chunks right next to each other (I‚Äôm using a 64-bit version of Python 3.7.1). However, it‚Äôs still a PyObject pointer, which means that it could be stored anywhere in memory. Files: ceval.c, object.c, descrobject.c Some GDB Pointers# If you want to dig around CPython like I did, there‚Äôs some setup required before you can start stepping through the code to find what functions run. After downloading the source and installing the required packages (I‚Äôd check the build instructions for your machine on the official repo), instead of doing just ./configure, run ./configure --with-pydebug. This creates a debug build of Python instead of a normal one, which allows you to attach GDB to the process. Then you run make to create the binary and debug it using GDB by running gdb python.\nAlso, if I wanted to debug my actual Python code, I had two strategies. Either a) create a conditional breakpoint where I wanted to stop in GDB using the current type-\u0026gt;tp_name string (and naming my class something weird), or b) actually writing the if statement into the code and putting the breakpoint within the statement. I ended up using the latter strategy more often, because I found that pasting in a long breakpoint conditional statement into gdb every time I reopened the debugger was pretty annoying (and I ended up memorizing b object.c:869 after enough run-throughs).\nConclusion# Overall, this article was kind of an excuse for me to look into CPython on my own time ü§§. I ended up learning a ton by downloading and building Python on my own and inserting printf statements in random places as well as using gdb. Also, I had heard the higher-level reasons for why to use __slots__ and actually wanted to test the claims for myself in a more empirical way. Hopefully you learned something new while reading! Leave any questions at the bottom and I‚Äôll try to answer them.\nReferences# StackOverflow: Usage of slots?\nData model - Python 3.7.1 Documentation\nGitHub: python/cpython\n","date":"2018-11-09","id":23,"permalink":"/posts/a-quick-dive-into-pythons-slots/","summary":"Originally posted on Medium.\nFor my first Medium article, we‚Äôre going to go into a quick and easy way to speed up your Python code (and pass those pesky HackerRank tests where you‚Äôre just a bit short on time!), as well as some of the technical implementation details for the curious.\n__slots__ is an attribute you can add to a Python class when defining it. You define slots with the possible attributes that an instance of an object can possess. Here‚Äôs how you use __slots__:\n","tags":["tech"],"title":"A Quick Dive Into Python's Slots"}]